{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VisionEngine.datasets import guppies\n",
    "from VisionEngine.utils.config import process_config\n",
    "from VisionEngine.utils import factory\n",
    "import sys\n",
    "import os\n",
    "from PIL import Image\n",
    "from itertools import product\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import warnings\n",
    "import numba\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 1000\n",
    "generations = 1000\n",
    "n_latents = 4\n",
    "latent_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/etheredge/Workspace/VisionEngine/VisionEngine/configs/guppy_nouveau_finetune_config.json\"\n",
    "config = process_config(config_file)\n",
    "checkpoint_path = \"/home/etheredge/Workspace/VisionEngine/checkpoints/guppy_nouveau_finetune/2020-230-11/guppy_nouveau_finetune.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_path = Path('../') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing VisionEngine.models.nouveau_vae_model\n",
      "getattr VAEModel\n",
      "Model: \"vlae\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "noise_layer (Sequential)        (None, 256, 256, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 524288), (No 38380171    noise_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "variational_layer (VariationalL (None, 10)           5242890     encoder[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "variational_layer_1 (Variationa (None, 10)           5242890     encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "variational_layer_2 (Variationa (None, 10)           5242890     encoder[1][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "variational_layer_3 (Variationa (None, 10)           5242890     encoder[1][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 256, 256, 3)  101197399   variational_layer[0][0]          \n",
      "                                                                 variational_layer_1[0][0]        \n",
      "                                                                 variational_layer_2[0][0]        \n",
      "                                                                 variational_layer_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "perceptual_loss_layer (Perceptu [(None, 256, 256, 3) 14714688    input_2[0][0]                    \n",
      "                                                                 decoder[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 175,263,818\n",
      "Trainable params: 160,396,369\n",
      "Non-trainable params: 14,867,449\n",
      "__________________________________________________________________________________________________\n",
      "Loading model checkpoint /home/etheredge/Workspace/VisionEngine/checkpoints/guppy_nouveau_finetune/2020-230-11/guppy_nouveau_finetune.hdf5 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [4:21:37,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "with tf.device(f\"GPU:{GPU}\"):\n",
    "    fitness = []\n",
    "    \n",
    "    BATCH_SIZE = 100  \n",
    "\n",
    "    orange_min = tf.constant([0.9, 0.55, 0.])\n",
    "    orange_min = tf.stack([tf.fill((BATCH_SIZE,256,256), orange_min[0]),\n",
    "              tf.fill((BATCH_SIZE,256,256), orange_min[1]),\n",
    "              tf.fill((BATCH_SIZE,256,256), orange_min[2])],\n",
    "              axis=-1)\n",
    "    orange_max = tf.constant([1., 0.75, 0.1])\n",
    "    orange_max = tf.stack([tf.fill((BATCH_SIZE,256,256), orange_max[0]),\n",
    "              tf.fill((BATCH_SIZE,256,256), orange_max[1]),\n",
    "              tf.fill((BATCH_SIZE,256,256), orange_max[2])],\n",
    "              axis=-1)\n",
    "    black_min = tf.constant([0., 0., 0., 0.8])\n",
    "    black_min = tf.stack([tf.fill((BATCH_SIZE,256,256), black_min[0]),\n",
    "              tf.fill((BATCH_SIZE,256,256), black_min[1]),\n",
    "              tf.fill((BATCH_SIZE,256,256), black_min[2])],\n",
    "              axis=-1)\n",
    "    black_max = tf.constant([0.2, 0.2, 0.2])\n",
    "    black_max = tf.stack([tf.fill((BATCH_SIZE,256,256), black_max[0]),\n",
    "              tf.fill((BATCH_SIZE,256,256), black_max[1]),\n",
    "              tf.fill((BATCH_SIZE,256,256), black_max[2])],\n",
    "              axis=-1)\n",
    "\n",
    "    weights = [1., 1.]\n",
    "\n",
    "    X = np.random.uniform(low=-100,high=100,size=(1000000, 4, 10))\n",
    "    \n",
    "    model = factory.create(\n",
    "                \"VisionEngine.models.\"+config.model.name\n",
    "                )(config)\n",
    "    model.load(checkpoint_path)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(X).batch(BATCH_SIZE)\n",
    "    for batch in tqdm.tqdm(ds):\n",
    "        batch = tf.reshape(batch, (4, BATCH_SIZE, 10))\n",
    "        x_hat = model.decoder([batch[0], batch[1], batch[2], batch[3]])\n",
    "        orange_vals = tf.math.logical_and(\n",
    "                tf.math.greater(x_hat,orange_min),\n",
    "                tf.math.less(x_hat, orange_max))\n",
    "        percent_orange = tf.math.divide(\n",
    "            tf.reduce_sum(tf.cast(tf.reduce_all(\n",
    "                    orange_vals,axis=(3)\n",
    "                ),dtype=tf.float32\n",
    "            ),axis=(1,2)),\n",
    "            np.product([256,256]))\n",
    "        black_vals = tf.math.logical_and(\n",
    "                tf.math.greater(x_hat,black_min),\n",
    "                tf.math.less(x_hat, black_max))\n",
    "        percent_black = tf.math.divide(\n",
    "            tf.reduce_sum(tf.cast(tf.reduce_all(\n",
    "                    black_vals,axis=(3)\n",
    "                ),dtype=tf.float32\n",
    "            ),axis=(1,2)),\n",
    "            np.product([256,256]))\n",
    "        # fitness is just a simple weighted sum here\n",
    "        fit = tf.math.reduce_sum([percent_orange*weights[0],percent_black*weights[1]],axis=0)\n",
    "        fitness.extend(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fitness.p\", \"wb\") as f:\n",
    "    pickle.dump(fitness, f)\n",
    "with open(\"X.p\", \"wb\") as f:\n",
    "    pickle.dump(X, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fitness.p\", \"rb\") as f:\n",
    "    fitness = pickle.load(f)\n",
    "with open(\"X.p\", \"rb\") as f:\n",
    "    X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_images(x):\n",
    "    outputs = [\n",
    "        model.model.get_layer('variational_layer').output,\n",
    "        model.model.get_layer('variational_layer_1').output,\n",
    "        model.model.get_layer('variational_layer_2').output,\n",
    "        model.model.get_layer('variational_layer_3').output\n",
    "    ]\n",
    "    encoder = tf.keras.Model(model.model.inputs, outputs)\n",
    "    return encoder.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_loader.use_generated = False\n",
    "config.data_loader.use_real = True\n",
    "\n",
    "config.data_loader.shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing VisionEngine.data_loaders.vae_data_loader\n",
      "getattr DataLoader\n"
     ]
    }
   ],
   "source": [
    "data_loader = factory.create(\n",
    "            \"VisionEngine.data_loaders.\"+config.data_loader.name\n",
    "            )(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_loader.use_generated = False\n",
    "config.data_loader.use_real = True\n",
    "\n",
    "config.data_loader.shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing VisionEngine.data_loaders.vae_data_loader\n",
      "getattr DataLoader\n"
     ]
    }
   ],
   "source": [
    "with tf.device(f\"GPU:{GPU}\"):\n",
    "    data_loader = factory.create(\n",
    "            \"VisionEngine.data_loaders.\"+config.data_loader.name\n",
    "            )(config)\n",
    "    parents = embed_images(data_loader.get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True, parallel=True)\n",
    "def fitness(parents, attribute_table, fitness_table):\n",
    "    '''\n",
    "    We define a simple fitness metric where the percent orange\n",
    "    and percent black contribute to higher fitness.\n",
    "    We use a lookup table of a predefined fitness landscape (for speed).\n",
    "    '''\n",
    "    fitness = []\n",
    "    for i in range(len(parents)):\n",
    "        fitness.append(np.argmin(np.sum(np.abs(attribute_table - parents[i]),axis=1)))\n",
    "\n",
    "    return fitness\n",
    "        \n",
    "\n",
    "def selection(parents, fitness, persistence=0.5, temperature=0.2):\n",
    "    '''\n",
    "    perform the selection step on the next generation of parents\n",
    "    '''\n",
    "    p_dist = np.array(fitness/np.sum(fitness)).flatten()\n",
    "    indexes = np.arange(len(parents))\n",
    "    survivors = parents[np.random.choice(indexes, int(population_size*persistence), p=p_dist)]\n",
    "    survivors = np.concatenate([survivors, parents[np.random.choice(indexes, int(population_size*temperature))]])\n",
    "    return survivors\n",
    "\n",
    "\n",
    "def mutate(child, mutation_rate=1, temperature=3):\n",
    "    '''\n",
    "    add mutations to offspring\n",
    "    '''\n",
    "    # add N random mutations to child with a given temperature\n",
    "    # destabilizing \n",
    "    for _ in range(mutation_rate):\n",
    "        z_i = np.random.choice(range(n_latents))\n",
    "        z_i_j = np.random.choice(range(latent_size))\n",
    "        child[z_i][0][z_i_j] = np.random.normal(loc=0, scale=temperature)\n",
    "    # stabilizing \n",
    "    for _ in range(mutation_rate):\n",
    "        z_i = np.random.choice(range(n_latents))\n",
    "        z_i_j = np.random.choice(range(latent_size))\n",
    "        child[z_i][0][z_i_j] = 0.\n",
    "\n",
    "    return child\n",
    "\n",
    "\n",
    "def crossing(parents):\n",
    "    '''\n",
    "    pass on alleles\n",
    "    '''\n",
    "    offspring = []\n",
    "    for _ in range(int(population_size - len(parents))):\n",
    "\n",
    "        # pick a couple of parents\n",
    "        parent1 = parents[np.random.choice(np.arange(len(parents)))]\n",
    "        parent2 = parents[np.random.choice(np.arange(len(parents)))]\n",
    "        \n",
    "        # randomly initialize child\n",
    "        child = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), 1)\n",
    "            ] * n_latents\n",
    "\n",
    "        # randomly combine traits from each parent with equal probability\n",
    "        locs = product(range(n_latents),range(latent_size))\n",
    "        for z_i, z_i_j in locs:\n",
    "            child[z_i][0][z_i_j] = np.random.choice([parent1[z_i][z_i_j], parent2[z_i][z_i_j]])\n",
    "        \n",
    "        child = mutate(child)\n",
    "        offspring.append(np.array(child).reshape(4,10))\n",
    "\n",
    "    return np.array(offspring)\n",
    "\n",
    "\n",
    "def main(parents, X, fitness):\n",
    "    # start with an initial population\n",
    "    parent_record = []\n",
    "#     parents = [\n",
    "#             np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), population_size)\n",
    "#             ] * n_latents\n",
    "    \n",
    "    \n",
    "    # load our fitness surface\n",
    "    attribute_table = X\n",
    "    fitness_table = fitness\n",
    "    \n",
    "    # reshape arrays\n",
    "    parents = np.transpose(np.array(parents), (1,0,2))\n",
    "#     parents = np.array(parents)\n",
    "#     attribute_table = np.transpose(attribute_table, (1,0,2))\n",
    "    # start the evolutionary process\n",
    "    for _ in tqdm.tqdm(range(generations)):\n",
    "        parent_fitness = fitness(parents.reshape(parents.shape[0],np.prod(parents.shape[1:])),\n",
    "                                 attribute_table.reshape(attribute_table.shape[0],np.prod(attribute_table.shape[1:])),\n",
    "                                 fitness_table)\n",
    "        survivors = selection(parents, parent_fitness)\n",
    "        offspring = crossing(survivors)  # also includes mutation\n",
    "        parents = np.concatenate([survivors,offspring])\n",
    "        parent_record.append(parents)\n",
    "        \n",
    "    return parent_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 294/1000 [42:12:27<101:24:06, 517.06s/it]"
     ]
    }
   ],
   "source": [
    "with tf.device(f'/device:GPU:{GPU}'):\n",
    "    pr = main(parents, X, fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pr.p\", \"wb\") as f:\n",
    "    pickle.dump(pr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(parents, attribute_table, fitness_table):\n",
    "    '''\n",
    "    We define a simple fitness metric where the percent orange\n",
    "    and percent black contribute to higher fitness.\n",
    "    We use a lookup table of a predefined fitness landscape (for speed).\n",
    "    '''\n",
    "    fitness = []\n",
    "    for i in range(len(parents)):\n",
    "        fitness.append(tf.math.argmin(tf.math.reduce_sum(tf.math.abs(attribute_table - parents[i]),axis=1)))\n",
    "\n",
    "    return fitness\n",
    "        \n",
    "\n",
    "def selection(parents, fitness, persistence=0.5, temperature=0.2):\n",
    "    '''\n",
    "    perform the selection step on the next generation of parents\n",
    "    '''\n",
    "    p_dist = np.array(fitness/np.sum(fitness)).flatten()\n",
    "    indexes = np.arange(len(parents))\n",
    "    survivors = parents[np.random.choice(indexes, int(population_size*persistence), p=p_dist)]\n",
    "    survivors = np.concatenate([survivors, parents[np.random.choice(indexes, int(population_size*temperature))]])\n",
    "    return survivors\n",
    "\n",
    "\n",
    "def mutate(child, mutation_rate=1, temperature=3):\n",
    "    '''\n",
    "    add mutations to offspring\n",
    "    '''\n",
    "    # add N random mutations to child with a given temperature\n",
    "    # destabilizing \n",
    "    for _ in range(mutation_rate):\n",
    "        z_i = np.random.choice(range(n_latents))\n",
    "        z_i_j = np.random.choice(range(latent_size))\n",
    "        child[z_i][0][z_i_j] = np.random.normal(loc=0, scale=temperature)\n",
    "    # stabilizing \n",
    "    for _ in range(mutation_rate):\n",
    "        z_i = np.random.choice(range(n_latents))\n",
    "        z_i_j = np.random.choice(range(latent_size))\n",
    "        child[z_i][0][z_i_j] = 0.\n",
    "\n",
    "    return child\n",
    "\n",
    "\n",
    "def crossing(parents):\n",
    "    '''\n",
    "    pass on alleles\n",
    "    '''\n",
    "    offspring = []\n",
    "    for _ in range(int(population_size - len(parents))):\n",
    "\n",
    "        # pick a couple of parents\n",
    "        parent1 = parents[np.random.choice(np.arange(len(parents)))]\n",
    "        parent2 = parents[np.random.choice(np.arange(len(parents)))]\n",
    "        \n",
    "        # randomly initialize child\n",
    "        child = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), 1)\n",
    "            ] * n_latents\n",
    "\n",
    "        # randomly combine traits from each parent with equal probability\n",
    "        locs = product(range(n_latents),range(latent_size))\n",
    "        for z_i, z_i_j in locs:\n",
    "            child[z_i][0][z_i_j] = np.random.choice([parent1[z_i][z_i_j], parent2[z_i][z_i_j]])\n",
    "        \n",
    "        child = mutate(child)\n",
    "        offspring.append(np.array(child).reshape(4,10))\n",
    "\n",
    "    return np.array(offspring)\n",
    "\n",
    "\n",
    "def main(parents, X, fitness):\n",
    "    # start with an initial population\n",
    "    parent_record = []\n",
    "#     parents = [\n",
    "#             np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), population_size)\n",
    "#             ] * n_latents\n",
    "    \n",
    "    \n",
    "    # load our fitness surface\n",
    "    attribute_table = X\n",
    "    fitness_table = fitness\n",
    "    \n",
    "    # reshape arrays\n",
    "    parents = np.transpose(np.array(parents), (1,0,2))\n",
    "#     parents = np.array(parents)\n",
    "#     attribute_table = np.transpose(attribute_table, (1,0,2))\n",
    "    # start the evolutionary process\n",
    "    for _ in tqdm.tqdm(range(generations)):\n",
    "        parent_fitness = fitness(parents.reshape(parents.shape[0],np.prod(parents.shape[1:])),\n",
    "                                 attribute_table.reshape(attribute_table.shape[0],np.prod(attribute_table.shape[1:])),\n",
    "                                 fitness_table)\n",
    "        survivors = selection(parents, parent_fitness)\n",
    "        offspring = crossing(survivors)  # also includes mutation\n",
    "        parents = np.concatenate([survivors,offspring])\n",
    "        parent_record.append(parents)\n",
    "        \n",
    "    return parent_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fitness_surface(model, overwrite=False):\n",
    "   \n",
    "    X = np.random.uniform(low=-100,high=100,size=(1000000, 4, 10))\n",
    "    \n",
    "    with tf.device(f\"GPU:{GPU}\"):\n",
    "        orange_min = tf.constant([0.9, 0.55, 0.])\n",
    "        orange_max = tf.constant([1., 0.75, 0.1])\n",
    "        black_min = tf.constant([0., 0., 0., 0.8])\n",
    "        black_max = tf.constant([[0.2, 0.2, 0.2]])\n",
    "        weights = [1., 1.]\n",
    "\n",
    "        fitness = []\n",
    "        \n",
    "        ds = tf.data.Dataset.from_tensor_slices(X).batch(32)\n",
    "        for batch in tqdm.tqdm(ds)\n",
    "            x_hat = model.decoder([latent_vars[0], latent_vars[1], latent_vars[2], latent_vars[3]])\n",
    "            orange_vals = tf.math.logical_and(\n",
    "                    tf.math.greater(x_hat,orange_min),\n",
    "                    tf.math.less(x_hat, orange_max))\n",
    "            percent_orange = tf.math.divide(\n",
    "                tf.reduce_sum(tf.cast(tf.reduce_all(\n",
    "                        orange_vals,axis=(3)\n",
    "                    ),dtype=tf.float32\n",
    "                ),axis=(1,2)),\n",
    "                np.product([256,256]))\n",
    "            black_vals = tf.math.logical_and(\n",
    "                    tf.math.greater(x_hat,black_min),\n",
    "                    tf.math.less(x_hat, black_max))\n",
    "            percent_black = tf.math.divide(\n",
    "                tf.reduce_sum(tf.cast(tf.reduce_all(\n",
    "                        black_vals,axis=(3)\n",
    "                    ),dtype=tf.float32\n",
    "                ),axis=(1,2)),\n",
    "                np.product([256,256]))\n",
    "            # fitness is just a simple weighted sum here\n",
    "            fit = tf.math.reduce_sum([percent_orange*weights[0],percent_black*weights[1]],axis=0)\n",
    "            fitness.append(fit)\n",
    "        return X, np.array(fitness)\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True, parallel=True)\n",
    "def fitness(parents, attribute_table, fitness_table):\n",
    "    '''\n",
    "    We define a simple fitness metric where the percent orange\n",
    "    and percent black contribute to higher fitness.\n",
    "    We use a lookup table of a predefined fitness landscape (for speed).\n",
    "    '''\n",
    "    fitness = []\n",
    "    for i in range(len(parents)):\n",
    "        fitness.append(np.argmin(np.sum(np.abs(attribute_table - parents[i]),axis=1)))\n",
    "\n",
    "    return fitness\n",
    "        \n",
    "\n",
    "def selection(parents, fitness, persistence=0.5, temperature=0.2):\n",
    "    '''\n",
    "    perform the selection step on the next generation of parents\n",
    "    '''\n",
    "    p_dist = np.array(fitness/np.sum(fitness)).flatten()\n",
    "    indexes = np.arange(len(parents))\n",
    "    survivors = parents[np.random.choice(indexes, int(population_size*persistence), p=p_dist)]\n",
    "    survivors = np.concatenate([survivors, parents[np.random.choice(indexes, int(population_size*temperature))]])\n",
    "    return survivors\n",
    "\n",
    "\n",
    "def mutate(child, mutation_rate=1, temperature=3):\n",
    "    '''\n",
    "    add mutations to offspring\n",
    "    '''\n",
    "    # add N random mutations to child with a given temperature\n",
    "    # destabilizing \n",
    "    for _ in range(mutation_rate):\n",
    "        z_i = np.random.choice(range(n_latents))\n",
    "        z_i_j = np.random.choice(range(latent_size))\n",
    "        child[z_i][0][z_i_j] = np.random.normal(loc=0, scale=temperature)\n",
    "    # stabilizing \n",
    "    for _ in range(mutation_rate):\n",
    "        z_i = np.random.choice(range(n_latents))\n",
    "        z_i_j = np.random.choice(range(latent_size))\n",
    "        child[z_i][0][z_i_j] = 0.\n",
    "\n",
    "    return child\n",
    "\n",
    "\n",
    "def crossing(parents):\n",
    "    '''\n",
    "    pass on alleles\n",
    "    '''\n",
    "    offspring = []\n",
    "    for _ in range(int(population_size - len(parents))):\n",
    "\n",
    "        # pick a couple of parents\n",
    "        parent1 = parents[np.random.choice(np.arange(len(parents)))]\n",
    "        parent2 = parents[np.random.choice(np.arange(len(parents)))]\n",
    "        \n",
    "        # randomly initialize child\n",
    "        child = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), 1)\n",
    "            ] * n_latents\n",
    "\n",
    "        # randomly combine traits from each parent with equal probability\n",
    "        locs = product(range(n_latents),range(latent_size))\n",
    "        for z_i, z_i_j in locs:\n",
    "            child[z_i][0][z_i_j] = np.random.choice([parent1[z_i][z_i_j], parent2[z_i][z_i_j]])\n",
    "        \n",
    "        child = mutate(child)\n",
    "        offspring.append(np.array(child).reshape(4,10))\n",
    "\n",
    "    return np.array(offspring)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # start with an initial population\n",
    "    parent_record = []\n",
    "#     parents = [\n",
    "#             np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), population_size)\n",
    "#             ] * n_latents\n",
    "    \n",
    "    \n",
    "    # load our fitness surface\n",
    "    attribute_table = X\n",
    "    fitness_table = fitness\n",
    "    \n",
    "    # reshape arrays\n",
    "    parents = np.transpose(np.array(parents), (1,0,2))\n",
    "    attribute_table = np.transpose(attribute_table, (1,0,2))\n",
    "    # start the evolutionary process\n",
    "    for _ in tqdm.tqdm(range(generations)):\n",
    "        parent_fitness = fitness(parents.reshape(parents.shape[0],np.prod(parents.shape[1:])),\n",
    "                                 attribute_table.reshape(attribute_table.shape[0],np.prod(attribute_table.shape[1:])),\n",
    "                                 fitness_table)\n",
    "        survivors = selection(parents, parent_fitness)\n",
    "        offspring = crossing(survivors)  # also includes mutation\n",
    "        parents = np.concatenate([survivors,offspring])\n",
    "        parent_record.append(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing VisionEngine.models.nouveau_vae_model\n",
      "getattr VAEModel\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10,524288] and type float on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc [Op:Add]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7ba391b8e2b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     model = factory.create(\n\u001b[1;32m      3\u001b[0m                 \u001b[0;34m\"VisionEngine.models.\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 )(config)\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/VisionEngine-0.1a0-py3.7.egg/VisionEngine/models/nouveau_vae_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVAEModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAEModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/VisionEngine-0.1a0-py3.7.egg/VisionEngine/models/nouveau_encoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/VisionEngine-0.1a0-py3.7.egg/VisionEngine/models/nouveau_decoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/VisionEngine-0.1a0-py3.7.egg/VisionEngine/models/nouveau_decoder.py\u001b[0m in \u001b[0;36mmake_decoder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f_4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mz_tilde_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_tilde_4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mz_tilde_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_tilde_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mz_tilde_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_tilde_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         trainable=True)\n\u001b[0m\u001b[1;32m   1166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                         shape=None):\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2598\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2599\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1432\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1565\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1567\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1569\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[1;32m    120\u001b[0m       \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0minit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mvariable_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     return op(\n\u001b[0;32m-> 1068\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    299\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/VisionEngine/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10,524288] and type float on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc [Op:Add]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_loader.use_generated = False\n",
    "config.data_loader.use_real = True\n",
    "\n",
    "config.data_loader.shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = factory.create(\n",
    "            \"VisionEngine.data_loaders.\"+config.data_loader.name\n",
    "            )(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " warnings.warn(\"We are evaluating 100000 points in our high dimension space. This may take a while, even with a powerful GPU...\")\n",
    "\n",
    "    def custom_loss(x,xhat):\n",
    "        return  .5 * tf.losses.mean_squared_error(Flatten()(x), Flatten()(xhat)) * np.prod(images[0].shape)\n",
    "    model_folder = '../models/vlae_mmd_all'\n",
    "    model = tf.keras.models.load_model(model_folder, custom_objects={'loss': custom_loss}, compile=False)\n",
    "    model.compile()\n",
    "\n",
    "    # evenly sample the latent space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('VisionEngine': conda)",
   "language": "python",
   "name": "python37664bitvisionengineconda838d932a94804d329f926ede73ba6fa3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
