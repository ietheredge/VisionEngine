{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VisionEngine.utils.config import process_config\n",
    "from VisionEngine.utils import factory\n",
    "from VisionEngine.utils.eval import (embed_images, \n",
    "                                     reconstruct_images,\n",
    "                                     reconstruct_images, \n",
    "                                     sample_likelihood)\n",
    "\n",
    "from VisionEngine.utils.plotting import imscatter\n",
    "\n",
    "from VisionEngine.utils.perceptual_loss import (make_perceptual_loss_model,\n",
    "                                                calculate_perceptual_distances)\n",
    "\n",
    "from VisionEngine.utils.disentanglement_score import dissentanglement_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from openTSNE import TSNE\n",
    "from openTSNE.callbacks import ErrorLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you only have one GPU, this must = 0\n",
    "GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = Path('../') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DHRL-Trained Guppies (Original Data)\n",
    "checkpoint_path = os.path.join(\n",
    "    os.getenv(\"VISIONENGINE_HOME\"),\n",
    "    \"checkpoints/guppies_DHRL_model.hdf5\"\n",
    ")\n",
    "config_file = os.path.join(\n",
    "    os.getenv(\"VISIONENGINE_HOME\"),\n",
    "    \"VisionEngine/configs/guppies_DHRL_config.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = process_config(config_file)\n",
    "\n",
    "# need to change a few config values\n",
    "config.data_loader.shuffle = False\n",
    "config.data_loader.use_generated = False\n",
    "config.data_loader.use_real = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device(f'/device:GPU:{GPU}'):\n",
    "    model = factory.create(\n",
    "                \"VisionEngine.models.\"+config.model.name\n",
    "                )(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load(checkpoint_path)\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = factory.create(\n",
    "            \"VisionEngine.data_loaders.\"+config.data_loader.name\n",
    "            )(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(f'/device:GPU:{GPU}'):\n",
    "    z = embed_images(data_loader.get_test_data(), model)\n",
    "    lh = sample_likelihood(data_loader.get_test_data(), model)\n",
    "    lh = (lh-tf.math.reduce_mean(lh))/tf.math.reduce_std(lh)\n",
    "    images_ = iter(data_loader.get_test_data())\n",
    "    images =  np.stack([image[0].numpy() for image in data_loader.get_plot_data()])\n",
    "    images = images.reshape(len(images),256*256*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Reconstructions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(f'/device:GPU:{GPU}'):\n",
    "    images = images_.next()[0]\n",
    "    x_hat = reconstruct_images(images)\n",
    "    ID = 2\n",
    "    plt.subplot(321)\n",
    "    plt.imshow(plot_im(images[ID]))\n",
    "    plt.subplot(322)\n",
    "    plt.imshow(plot_im(x_hat[ID]))\n",
    "    images = images_.next()[0]\n",
    "    x_hat = reconstruct_images(images)\n",
    "    ID = 2\n",
    "    plt.subplot(323)\n",
    "    plt.imshow(plot_im(images[ID]))\n",
    "    plt.subplot(324)\n",
    "    plt.imshow(plot_im(x_hat[ID]))\n",
    "    images = images_.next()[0]\n",
    "    x_hat = reconstruct_images(images)\n",
    "    ID = 2\n",
    "    plt.subplot(325)\n",
    "    plt.imshow(plot_im(images[ID]))\n",
    "    plt.subplot(326)\n",
    "    plt.imshow(plot_im(x_hat[ID]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Sample Likelihood**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "embedding = vision_engine_embedding\n",
    "plt.subplot(121)\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.15);\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.5,\n",
    "        c=lh, cmap=cmap, s=400, rasterized=True)\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perception = []\n",
    "with tf.device('/device:cpu:0'):\n",
    "    perceptual_model = make_perceptual_loss_model((256,256,3))\n",
    "    for batch in data_loader.get_test_data().batch(16):\n",
    "        perception.extend(perceptual_model.predict(batch))\n",
    "    perceptual_distances = calculate_perceptual_distances(np.array(perception))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Perceptual Distance, Raw Pixel, and Our Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perceptual_embedding = TSNE(callbacks=ErrorLogger(),  n_jobs=8).fit(perceptual_distances.T)\n",
    "raw_image_embedding = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit()\n",
    "vision_engine_embedding = TSNE(callbacks=ErrorLogger(), n_jobs=8).fit(np.concatenate([z[0],z[1],z[2],z[3]], axis=1))\n",
    "h1 = TSNE(callbacks=ErrorLogger(), n_jobs=8).fit(z[0])\n",
    "h2 = TSNE(callbacks=ErrorLogger(),  n_jobs=8).fit(z[1])\n",
    "h3 = TSNE(callbacks=ErrorLogger(),n_jobs=8).fit(z[2])\n",
    "h4 = TSNE(callbacks=ErrorLogger(),  n_jobs=8).fit(z[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,10))\n",
    "\n",
    "classnames, indices = np.unique( labels, return_inverse=True)\n",
    "N = len(classnames)\n",
    "cmap = plt.cm.rainbow\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "plt.subplot(141)\n",
    "embedding = h1\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "plt.subplot(142)\n",
    "embedding = h2\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "plt.subplot(143)\n",
    "embedding = h3\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "plt.subplot(144)\n",
    "embedding = h4\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "plt.subplot(231)\n",
    "plt.title('Raw Pixel Distribution')\n",
    "embedding = raw_image_embedding\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.15);\n",
    "plt.subplot(234)\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400, rasterized=True)\n",
    "plt.subplot(232)\n",
    "plt.title('Perceptual Loss Metric')\n",
    "embedding = perceptual_embedding \n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.15);\n",
    "plt.subplot(235)\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400, rasterized=True)\n",
    "plt.subplot(233)\n",
    "plt.title('DHRL (Our method)')\n",
    "embedding = vision_engine_embedding\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.15);\n",
    "plt.subplot(236)\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400, rasterized=True)\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measure Disentanglement and Completeness Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(f'/device:GPU:{GPU}'):\n",
    "    labels = np.hstack([image[1] for image in data_loader.get_test_data()])\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(labels)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    inputs = onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 3\n",
    "disent_w_avg, complete_avg = dissentanglement_score(z, inputs, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(disent_w_avg, complete_avg)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('VisionEngine': conda)",
   "language": "python",
   "name": "python37664bitvisionengineconda838d932a94804d329f926ede73ba6fa3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
