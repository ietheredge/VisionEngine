{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = 10\n",
    "generations = 100\n",
    "n_latents = 4\n",
    "latent_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent1 = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), 1)\n",
    "            ] * n_latents\n",
    "parent2 = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), 1)\n",
    "            ] * n_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(parent1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.random.uniform(-4, 4, 1000) * latent_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(-4, 4, 1000).shape *4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform = [np.array([np.random.uniform(-4, 4, 1000)] * latent_size)] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITER = product(np.linspace(-4, 4, 10),np.linspace(-4, 4, 10),np.linspace(-4, 4, 10),np.linspace(-4, 4, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "del big_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sampling = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([4] * latent_size), 10000)\n",
    "            ] * n_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 10)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sampling[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_array = np.array(list(ITER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITER = product([big_array] * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_array = np.array(list(ITER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 10000, 4)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigger_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(x,xhat):\n",
    "    return  .5 * tf.losses.mean_squared_error(Flatten()(x), Flatten()(xhat)) * np.prod(images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output output_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to output_1.\n"
     ]
    }
   ],
   "source": [
    "model_folder = '../models/vlae_mmd_all'\n",
    "model = tf.keras.models.load_model(model_folder, custom_objects={'loss': custom_loss}, compile=False)\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 10)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(low=-4,high=4,size=(4, 100000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_images(z):\n",
    "    return model.get_layer('decoder').predict(z, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [32:26<00:00, 51.36it/s]\n"
     ]
    }
   ],
   "source": [
    "fitness = []\n",
    "with tf.device(\"GPU:0\"):\n",
    "    orange_min = tf.constant([0.9, 0.55, 0.])\n",
    "    orange_max = tf.constant([1., 0.75, 0.1])\n",
    "    black_min = tf.constant([0., 0., 0.])\n",
    "    black_max = tf.constant([[0.2, 0.2, 0.2]])\n",
    "    weights = [1., 1.]\n",
    "    for i in tqdm.tqdm(range(100000)):\n",
    "        x_hat = model.get_layer('decoder').predict([np.expand_dims(X[0,i],axis=0),\n",
    "                                                    np.expand_dims(X[1,i],axis=0),\n",
    "                                                    np.expand_dims(X[2,i],axis=0),\n",
    "                                                    np.expand_dims(X[3,i],axis=0)])\n",
    "        orange_vals = tf.math.logical_and(\n",
    "                tf.math.greater(x_hat,orange_min),\n",
    "                tf.math.less(x_hat, orange_max))\n",
    "        percent_orange = tf.math.divide(\n",
    "            tf.reduce_sum(tf.cast(tf.reduce_all(\n",
    "                    orange_vals,axis=(3)\n",
    "                ),dtype=tf.float32\n",
    "            ),axis=(1,2)),\n",
    "            np.product([256,256]))\n",
    "        black_vals = tf.math.logical_and(\n",
    "                tf.math.greater(x_hat,black_min),\n",
    "                tf.math.less(x_hat, black_max))\n",
    "        percent_black = tf.math.divide(\n",
    "            tf.reduce_sum(tf.cast(tf.reduce_all(\n",
    "                    black_vals,axis=(3)\n",
    "                ),dtype=tf.float32\n",
    "            ),axis=(1,2)),\n",
    "            np.product([256,256]))\n",
    "        # fitness is just a simple weighted sum here\n",
    "        fit = tf.math.reduce_sum([percent_orange*weights[0],percent_black*weights[1]],axis=0)\n",
    "        fitness.append(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = np.array(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4000000 into shape (100000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-3cc850ba3a48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4000000 into shape (100000,)"
     ]
    }
   ],
   "source": [
    "np.abs(attribute_table - parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(attribute_table.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12557\n",
      "24092\n",
      "72973\n",
      "34960\n",
      "1820\n",
      "34963\n",
      "5021\n",
      "27796\n",
      "70654\n",
      "3825\n",
      "25376\n",
      "23207\n",
      "47642\n",
      "94382\n",
      "65936\n",
      "6111\n",
      "27200\n",
      "73393\n",
      "45172\n",
      "46367\n",
      "65703\n",
      "65936\n",
      "51228\n",
      "12955\n",
      "27890\n",
      "22763\n",
      "27796\n",
      "15874\n",
      "12955\n",
      "13904\n",
      "66175\n",
      "79177\n",
      "94483\n",
      "76706\n",
      "42537\n",
      "70295\n",
      "84463\n",
      "11411\n",
      "50681\n",
      "15874\n",
      "33199\n",
      "42853\n",
      "84463\n",
      "30003\n",
      "39378\n",
      "59494\n",
      "11411\n",
      "80613\n",
      "7168\n",
      "51228\n",
      "37969\n",
      "26507\n",
      "4392\n",
      "94483\n",
      "38356\n",
      "47642\n",
      "11411\n",
      "11364\n",
      "27200\n",
      "93690\n",
      "5480\n",
      "15874\n",
      "15874\n",
      "30181\n",
      "29740\n",
      "65936\n",
      "38575\n",
      "85091\n",
      "6260\n",
      "15874\n",
      "58218\n",
      "38163\n",
      "45172\n",
      "31352\n",
      "77217\n",
      "71386\n",
      "27796\n",
      "56170\n",
      "56170\n",
      "27200\n",
      "70943\n",
      "59178\n",
      "42853\n",
      "50681\n",
      "94382\n",
      "1700\n",
      "53971\n",
      "73393\n",
      "47642\n",
      "29998\n",
      "45172\n",
      "30003\n",
      "76049\n",
      "87760\n",
      "15874\n",
      "65936\n",
      "25140\n",
      "51228\n",
      "85412\n",
      "72391\n",
      "15634\n",
      "18892\n",
      "27890\n",
      "5480\n",
      "84755\n",
      "62117\n",
      "66175\n",
      "6260\n",
      "70295\n",
      "46224\n",
      "70943\n",
      "21669\n",
      "84463\n",
      "12557\n",
      "27200\n",
      "38575\n",
      "94483\n",
      "63092\n",
      "27796\n",
      "66175\n",
      "93690\n",
      "12676\n",
      "59178\n",
      "60610\n",
      "72929\n",
      "17972\n",
      "9792\n",
      "35200\n",
      "5061\n",
      "5061\n",
      "94608\n",
      "6111\n",
      "45172\n",
      "73393\n",
      "95465\n",
      "11364\n",
      "385\n",
      "58218\n",
      "4392\n",
      "48996\n",
      "94483\n",
      "50681\n",
      "68583\n",
      "84463\n",
      "17972\n",
      "40959\n",
      "13496\n",
      "63413\n",
      "47642\n",
      "40231\n",
      "26807\n",
      "27796\n",
      "77293\n",
      "42451\n",
      "11364\n",
      "9779\n",
      "93988\n",
      "26807\n",
      "48996\n",
      "87136\n",
      "60233\n",
      "72973\n",
      "11364\n",
      "94483\n",
      "27796\n",
      "11364\n",
      "59114\n",
      "14205\n",
      "66175\n",
      "94483\n",
      "42451\n",
      "969\n",
      "5480\n",
      "13904\n",
      "104\n",
      "27796\n",
      "66175\n",
      "90527\n",
      "13496\n",
      "29001\n",
      "73570\n",
      "83586\n",
      "40049\n",
      "15874\n",
      "76706\n",
      "5483\n",
      "48108\n",
      "1700\n",
      "73393\n",
      "26807\n",
      "42537\n",
      "49865\n",
      "1679\n",
      "48108\n",
      "73393\n",
      "18892\n",
      "39931\n",
      "13496\n",
      "49865\n",
      "72973\n",
      "27796\n",
      "47642\n",
      "11411\n",
      "6260\n",
      "19728\n",
      "86398\n",
      "27796\n",
      "51533\n",
      "34800\n",
      "48996\n",
      "5131\n",
      "51228\n",
      "94483\n",
      "27200\n",
      "4392\n",
      "18444\n",
      "99501\n",
      "11364\n",
      "41653\n",
      "5744\n",
      "83698\n",
      "27200\n",
      "25376\n",
      "6260\n",
      "94322\n",
      "84533\n",
      "1700\n",
      "96049\n",
      "27796\n",
      "68691\n",
      "47642\n",
      "48108\n",
      "76549\n",
      "70943\n",
      "8438\n",
      "34960\n",
      "13904\n",
      "25007\n",
      "46494\n",
      "38575\n",
      "74033\n",
      "5483\n",
      "24092\n",
      "47642\n",
      "11364\n",
      "13904\n",
      "84463\n",
      "34095\n",
      "50681\n",
      "15874\n",
      "38356\n",
      "39931\n",
      "57368\n",
      "77217\n",
      "24092\n",
      "94382\n",
      "6076\n",
      "47642\n",
      "73393\n",
      "21417\n",
      "32384\n",
      "28356\n",
      "71951\n",
      "92468\n",
      "59076\n",
      "13904\n",
      "37246\n",
      "85281\n",
      "5131\n",
      "96049\n",
      "87743\n",
      "12693\n",
      "1700\n",
      "27200\n",
      "51671\n",
      "94382\n",
      "87760\n",
      "39931\n",
      "95108\n",
      "33199\n",
      "5483\n",
      "7168\n",
      "84755\n",
      "10435\n",
      "27796\n",
      "13904\n",
      "59114\n",
      "51223\n",
      "72929\n",
      "12955\n",
      "9779\n",
      "66913\n",
      "27796\n",
      "95108\n",
      "59076\n",
      "25140\n",
      "74821\n",
      "59178\n",
      "28356\n",
      "7168\n",
      "5061\n",
      "35200\n",
      "84755\n",
      "964\n",
      "50681\n",
      "80938\n",
      "969\n",
      "72391\n",
      "8939\n",
      "47642\n",
      "65936\n",
      "13496\n",
      "5483\n",
      "7168\n",
      "12402\n",
      "1679\n",
      "10777\n",
      "17972\n",
      "52602\n",
      "50211\n",
      "25376\n",
      "19191\n",
      "32455\n",
      "14612\n",
      "49865\n",
      "94483\n",
      "47642\n",
      "74007\n",
      "8346\n",
      "76636\n",
      "42380\n",
      "12693\n",
      "969\n",
      "30789\n",
      "46199\n",
      "47642\n",
      "71386\n",
      "24506\n",
      "46224\n",
      "17972\n",
      "11364\n",
      "84755\n",
      "25140\n",
      "199\n",
      "13496\n",
      "27796\n",
      "11364\n",
      "5061\n",
      "11411\n",
      "15033\n",
      "12955\n",
      "33199\n",
      "32455\n",
      "7168\n",
      "84463\n",
      "65936\n",
      "73981\n",
      "57368\n",
      "19728\n",
      "17972\n",
      "47328\n",
      "46494\n",
      "79177\n",
      "27200\n",
      "51223\n",
      "31352\n",
      "20509\n",
      "19900\n",
      "8639\n",
      "94382\n",
      "95513\n",
      "34963\n",
      "44714\n",
      "1700\n",
      "20509\n",
      "51228\n",
      "27200\n",
      "29998\n",
      "27796\n",
      "12955\n",
      "25425\n",
      "88569\n",
      "4889\n",
      "61647\n",
      "27796\n",
      "5483\n",
      "63413\n",
      "86398\n",
      "58056\n",
      "51223\n",
      "21669\n",
      "66412\n",
      "85398\n",
      "11364\n",
      "77217\n",
      "27796\n",
      "19728\n",
      "65370\n",
      "38163\n",
      "33199\n",
      "37969\n",
      "76833\n",
      "72642\n",
      "11364\n",
      "4392\n",
      "47642\n",
      "93988\n",
      "88536\n",
      "40049\n",
      "18535\n",
      "47642\n",
      "17972\n",
      "66913\n",
      "86398\n",
      "23494\n",
      "80685\n",
      "71386\n",
      "15874\n",
      "13904\n",
      "27200\n",
      "40049\n",
      "4656\n",
      "86483\n",
      "78484\n",
      "77217\n",
      "65370\n",
      "7168\n",
      "58218\n",
      "51228\n",
      "84474\n",
      "70295\n",
      "34960\n",
      "66913\n",
      "5061\n",
      "85398\n",
      "38163\n",
      "25376\n",
      "26807\n",
      "79177\n",
      "27200\n",
      "77217\n",
      "24092\n",
      "76701\n",
      "84463\n",
      "19136\n",
      "25376\n",
      "10345\n",
      "8438\n",
      "15874\n",
      "41653\n",
      "63413\n",
      "27209\n",
      "94025\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-3e75d041ef61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute_table\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attribute_table=attribute_table.reshape(attribute_table.shape[0],np.prod(attribute_table.shape[1:]))\n",
    "parents=parents.reshape(parents.shape[0],np.prod(parents.shape[1:]))\n",
    "for parent in parents:\n",
    "    print(np.sum(np.abs(attribute_table - parent),axis=1).argmin(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True, parallel=True)\n",
    "def fitness(parents, attribute_table, fitness_table):\n",
    "    '''\n",
    "    We define a simple fitness metric where the percent orange\n",
    "    and percent black contribute to higher fitness.\n",
    "    We use a lookup table of a predefined fitness landscape (for speed).\n",
    "    '''\n",
    "    fitness = []\n",
    "    for i in range(len(parents)):\n",
    "        fitness.append(np.argmin(np.sum(np.abs(attribute_table - parents[i]),axis=1)))\n",
    "\n",
    "    return fitness\n",
    "        \n",
    "def selection(parents, fitness, persistence=0.5, temperature=0.2):\n",
    "    '''\n",
    "    perform the selection step on the next generation of parents\n",
    "    '''\n",
    "    p_dist = np.array(fitness/np.sum(fitness)).flatten()\n",
    "    indexes = np.arange(len(parents))\n",
    "    survivors = parents[np.random.choice(indexes, int(population_size*persistence), p=p_dist)]\n",
    "    survivors = np.concatenate([survivors, parents[np.random.choice(indexes, int(population_size*temperature))]])\n",
    "    return survivors\n",
    "\n",
    "def mutate(child, mutation_rate=1, temperature=3):\n",
    "    '''\n",
    "    add mutations to offspring\n",
    "    '''\n",
    "    # add N random mutations to child with a given temperature\n",
    "    # destabilizing \n",
    "    for _ in range(mutation_rate):\n",
    "        z_i = np.random.choice(range(n_latents))\n",
    "        z_i_j = np.random.choice(range(latent_size))\n",
    "        child[z_i][0][z_i_j] = np.random.normal(loc=0, scale=temperature)\n",
    "    # stabilizing \n",
    "    for _ in range(mutation_rate):\n",
    "        z_i = np.random.choice(range(n_latents))\n",
    "        z_i_j = np.random.choice(range(latent_size))\n",
    "        child[z_i][0][z_i_j] = 0.\n",
    "\n",
    "    return child\n",
    "\n",
    "def crossing(parents):\n",
    "    '''\n",
    "    pass on alleles\n",
    "    '''\n",
    "    offspring = []\n",
    "    for _ in range(int(population_size - len(parents))):\n",
    "\n",
    "        # pick a couple of parents\n",
    "        parent1 = parents[np.random.choice(np.arange(len(parents)))]\n",
    "        parent2 = parents[np.random.choice(np.arange(len(parents)))]\n",
    "        \n",
    "        # randomly initialize child\n",
    "        child = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), 1)\n",
    "            ] * n_latents\n",
    "\n",
    "        # randomly combine traits from each parent with equal probability\n",
    "        locs = product(range(n_latents),range(latent_size))\n",
    "        for z_i, z_i_j in locs:\n",
    "            child[z_i][0][z_i_j] = np.random.choice([parent1[z_i][z_i_j], parent2[z_i][z_i_j]])\n",
    "        \n",
    "        child = mutate(child)\n",
    "        offspring.append(np.array(child).reshape(4,10))\n",
    "\n",
    "    return np.array(offspring)\n",
    "\n",
    "def main():\n",
    "    # start with an initial population\n",
    "    parent_record = []\n",
    "    parents = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), population_size)\n",
    "            ] * n_latents\n",
    "    \n",
    "    \n",
    "    # load our fitness surface\n",
    "    attribute_table = X\n",
    "    fitness_table = fit\n",
    "    \n",
    "    # reshape arrays\n",
    "    parents = np.transpose(np.array(parents), (1,0,2))\n",
    "    attribute_table = np.transpose(attribute_table, (1,0,2))\n",
    "    # start the evolutionary process\n",
    "    for _ in tqdm.tqdm(range(generations)):\n",
    "        parent_fitness = fitness(parents.reshape(parents.shape[0],np.prod(parents.shape[1:])),\n",
    "                                 attribute_table.reshape(attribute_table.shape[0],np.prod(attribute_table.shape[1:])),\n",
    "                                 fitness_table)\n",
    "        survivors = selection(parents, parent_fitness)\n",
    "        offspring = crossing(survivors)  # also includes mutation\n",
    "        parents = np.concatenate([survivors,offspring])\n",
    "        parent_record.append(parents)\n",
    "    return parent_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1000, 10)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), population_size)\n",
    "            ] * n_latents\n",
    "np.array(test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "parent_record = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parent_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = np.transpose(np.array(parent_record), (0,2,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4, 1000, 10)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.concatenate([z_ for z_ in X], axis=1)\n",
    "embedding = TSNE(n_components=2).fit_transform(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 40)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:23<6:26:27, 23.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 2/1000 [00:44<6:16:46, 22.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 3/1000 [01:07<6:17:58, 22.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-e66dcc822354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     parent_fitness = fitness(parents.reshape(parents.shape[0],np.prod(parents.shape[1:])),\n\u001b[1;32m     16\u001b[0m                              \u001b[0mattribute_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                              fitness_table)\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0msurvivors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_fitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moffspring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurvivors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# also includes mutation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parents = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), population_size)\n",
    "            ] * n_latents\n",
    "    \n",
    "    \n",
    "# load our fitness surface\n",
    "attribute_table = X\n",
    "fitness_table = fit\n",
    "\n",
    "# reshape arrays\n",
    "parents = np.transpose(np.array(parents), (1,0,2))\n",
    "attribute_table = np.transpose(attribute_table, (1,0,2))\n",
    "# start the evolutionary process\n",
    "for _ in tqdm.tqdm(range(generations)):\n",
    "    parent_fitness = fitness(parents.reshape(parents.shape[0],np.prod(parents.shape[1:])),\n",
    "                             attribute_table.reshape(attribute_table.shape[0],np.prod(attribute_table.shape[1:])),\n",
    "                             fitness_table)\n",
    "    survivors = selection(parents, parent_fitness)\n",
    "    offspring = crossing(survivors)  # also includes mutation\n",
    "    parents = np.concatenate([survivors, offspring])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "population_size = 1000\n",
    "generations = 1000\n",
    "n_latents = 4\n",
    "latent_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), population_size)\n",
    "            ] * n_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_table = X\n",
    "fitness_table = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = np.transpose(np.array(parents), (1,0,2))\n",
    "attribute_table = np.transpose(attribute_table, (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4, 10)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(attribute_table - parents[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47642"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sum(np.abs(attribute_table - parents[0]),axis=(1,2))).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(parents, attribute_table, fitness_table):\n",
    "    '''\n",
    "    We define a simple fitness metric where the percent orange\n",
    "    and percent black contribute to higher fitness.\n",
    "    We use a lookup table of a predefined fitness landscape (for speed).\n",
    "    '''\n",
    "    fitness = np.zeros(len(parents))\n",
    "    \n",
    "    for i, parent in enumerate(parents):\n",
    "        idx = (np.sum(np.abs(attribute_table - parent),axis=(1,2))).argmin()\n",
    "        fitness[i] = fitness_table[idx]\n",
    "\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(parents, fitness, persistence=0.5, temperature=0.2):\n",
    "    '''\n",
    "    perform the selection step on the next generation of parents\n",
    "    '''\n",
    "    p_dist = fitness/np.sum(fitness)\n",
    "    indexes = np.arange(len(parents))\n",
    "    survivors = parents[np.random.choice(indexes, int(population_size*persistence), p=p_dist)]\n",
    "    survivors = np.concatenate([survivors, parents[np.random.choice(indexes, int(population_size*temperature))]])\n",
    "    return survivors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossing(parents):\n",
    "    '''\n",
    "    pass on alleles\n",
    "    '''\n",
    "    offspring = []\n",
    "    for _ in range(int(population_size - len(parents))):\n",
    "\n",
    "        # pick a couple of parents\n",
    "        parent1 = parents[np.random.choice(np.arange(len(parents)))]\n",
    "        parent2 = parents[np.random.choice(np.arange(len(parents)))]\n",
    "        \n",
    "        # randomly initialize child\n",
    "        child = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), 1)\n",
    "            ] * n_latents\n",
    "\n",
    "        # randomly combine traits from each parent with equal probability\n",
    "        locs = product(range(n_latents),range(latent_size))\n",
    "        for z_i, z_i_j in locs:\n",
    "            child[z_i][0][z_i_j] = np.random.choice([parent1[z_i][z_i_j], parent1[z_i][z_i_j]])\n",
    "        \n",
    "        child = mutate(child)\n",
    "        offspring.append(np.array(child).reshape(4,10))\n",
    "\n",
    "    return np.array(offspring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_fitness = fitness(parents, attribute_table, fitness_table)\n",
    "# survivors = selection(parents, parent_fitness)\n",
    "offspring = crossing(survivors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 4, 10)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(offspring).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 4, 10)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survivors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survivors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_fitness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100000, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(parents, (1, 0, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness = []\n",
    "space = []\n",
    "for _ in range(100):\n",
    "    random_sampling = [\n",
    "                np.random.multivariate_normal([0] * latent_size,np.diag([4] * latent_size), 100)\n",
    "                ] * n_latents\n",
    "    with tf.device(\"GPU:0\"):\n",
    "        orange_min = tf.constant([0.9, 0.55, 0.])\n",
    "        orange_max = tf.constant([1., 0.75, 0.1])\n",
    "        black_min = tf.constant([0., 0., 0.])\n",
    "        black_max = tf.constant([[0.2, 0.2, 0.2]])\n",
    "        weights = [1., 1.]\n",
    "\n",
    "        x_hat = model.get_layer('decoder').predict(random_sampling)\n",
    "        orange_vals = tf.math.logical_and(\n",
    "                tf.math.greater(x_hat,orange_min),\n",
    "                tf.math.less(x_hat, orange_max))\n",
    "        percent_orange = tf.math.divide(\n",
    "            tf.reduce_sum(tf.cast(tf.reduce_all(\n",
    "                    orange_vals,axis=(3)\n",
    "                ),dtype=tf.float32\n",
    "            ),axis=(1,2)),\n",
    "            np.product([256,256]))\n",
    "        black_vals = tf.math.logical_and(\n",
    "                tf.math.greater(x_hat,black_min),\n",
    "                tf.math.less(x_hat, black_max))\n",
    "        percent_black = tf.math.divide(\n",
    "            tf.reduce_sum(tf.cast(tf.reduce_all(\n",
    "                    black_vals,axis=(3)\n",
    "                ),dtype=tf.float32\n",
    "            ),axis=(1,2)),\n",
    "            np.product([256,256]))\n",
    "        # fitness is just a simple weighted sum here\n",
    "        fit = tf.math.reduce_sum([percent_orange*weights[0],percent_black*weights[1]],axis=0)\n",
    "    space.append(np.array(random_sampling))\n",
    "    fitness.append(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=44429, shape=(100,), dtype=float32, numpy=\n",
       "array([0.01226807, 0.01716614, 0.02246094, 0.0112915 , 0.01858521,\n",
       "       0.01182556, 0.0196991 , 0.0213623 , 0.02508545, 0.01152039,\n",
       "       0.02233887, 0.02745056, 0.01451111, 0.01927185, 0.01239014,\n",
       "       0.01872253, 0.02212524, 0.03056335, 0.0219574 , 0.04077148,\n",
       "       0.02485657, 0.02165222, 0.03707886, 0.02677917, 0.02763367,\n",
       "       0.0171814 , 0.01983643, 0.02645874, 0.0459137 , 0.02339172,\n",
       "       0.01579285, 0.02206421, 0.02986145, 0.00428772, 0.03051758,\n",
       "       0.0222168 , 0.02642822, 0.03146362, 0.01687622, 0.01934814,\n",
       "       0.01571655, 0.02914429, 0.01248169, 0.01495361, 0.02377319,\n",
       "       0.02763367, 0.03549194, 0.03387451, 0.01985168, 0.02806091,\n",
       "       0.01025391, 0.02044678, 0.02424622, 0.03086853, 0.02412415,\n",
       "       0.03334045, 0.01608276, 0.03001404, 0.03968811, 0.01586914,\n",
       "       0.02154541, 0.03688049, 0.02923584, 0.01937866, 0.02227783,\n",
       "       0.03286743, 0.03192139, 0.03919983, 0.01968384, 0.03735352,\n",
       "       0.025177  , 0.02870178, 0.01222229, 0.03237915, 0.02046204,\n",
       "       0.01313782, 0.02648926, 0.01574707, 0.01821899, 0.03352356,\n",
       "       0.01243591, 0.02433777, 0.03535461, 0.02284241, 0.01797485,\n",
       "       0.0274353 , 0.0436554 , 0.02410889, 0.02642822, 0.01527405,\n",
       "       0.01689148, 0.02053833, 0.01170349, 0.02293396, 0.01913452,\n",
       "       0.02241516, 0.01725769, 0.01278687, 0.01972961, 0.00827026],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10, 1000)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(uniform).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "child = [\n",
    "            np.random.multivariate_normal([0] * latent_size,np.diag([1] * latent_size), 1)\n",
    "            ] * n_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.98105804,  0.58213917,  0.97734226, -1.65639373,  1.76520232,\n",
       "          0.56862362, -0.03511802,  2.50743429,  0.56445633, -0.59183489]]),\n",
       " array([[ 0.98105804,  0.58213917,  0.97734226, -1.65639373,  1.76520232,\n",
       "          0.56862362, -0.03511802,  2.50743429,  0.56445633, -0.59183489]]),\n",
       " array([[ 0.98105804,  0.58213917,  0.97734226, -1.65639373,  1.76520232,\n",
       "          0.56862362, -0.03511802,  2.50743429,  0.56445633, -0.59183489]]),\n",
       " array([[ 0.98105804,  0.58213917,  0.97734226, -1.65639373,  1.76520232,\n",
       "          0.56862362, -0.03511802,  2.50743429,  0.56445633, -0.59183489]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = product(range(n_latents),range(latent_size))\n",
    "for z_i, z_i_j in locs:\n",
    "    child[z_i][0][z_i_j] = np.random.choice([parent1[z_i][0][z_i_j],parent1[z_i][0][z_i_j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.50090697, -0.44479713, -0.47266571, -0.10057938,  0.69694359,\n",
       "          0.29683328,  0.13111999,  0.08067502, -0.09645291, -0.06237675]]),\n",
       " array([[ 0.50090697, -0.44479713, -0.47266571, -0.10057938,  0.69694359,\n",
       "          0.29683328,  0.13111999,  0.08067502, -0.09645291, -0.06237675]]),\n",
       " array([[ 0.50090697, -0.44479713, -0.47266571, -0.10057938,  0.69694359,\n",
       "          0.29683328,  0.13111999,  0.08067502, -0.09645291, -0.06237675]]),\n",
       " array([[ 0.50090697, -0.44479713, -0.47266571, -0.10057938,  0.69694359,\n",
       "          0.29683328,  0.13111999,  0.08067502, -0.09645291, -0.06237675]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
