{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VisionEngine.datasets import guppies\n",
    "from VisionEngine.utils.config import process_config\n",
    "from VisionEngine.utils import factory\n",
    "import sys\n",
    "import os\n",
    "from PIL import Image\n",
    "from itertools import product\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/etheredge/Workspace/VisionEngine/checkpoints/guppy_periodic/2020-213-11/guppy_periodic.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/home/etheredge/Workspace/VisionEngine/VisionEngine/configs/guppy_periodic_config.json'\n",
    "config = process_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = Path('../') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = factory.create(\n",
    "            \"VisionEngine.models.\"+config.model.name\n",
    "            )(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.data_loader.use_generated = True\n",
    "# config.data_loader.use_real = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = factory.create(\n",
    "            \"VisionEngine.data_loaders.\"+config.data_loader.name\n",
    "            )(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_im(img):\n",
    "    if config.model.last_activation == 'tanh':\n",
    "        img * 0.5 + 0.5\n",
    "        return img\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def plot_img_attributions(image,\n",
    "                          attribution_mask,\n",
    "                          H=0,\n",
    "                          z_i=0,\n",
    "                          cmap=None,\n",
    "                          overlay_alpha=0.4):\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, squeeze=False, figsize=(12, 4))\n",
    "\n",
    "    axs[0, 1].set_title('Original sample Output')\n",
    "    axs[0, 1].imshow(image)\n",
    "    axs[0, 1].axis('off')\n",
    "\n",
    "    axs[0, 2].set_title(f'Attribution mask: {H}, {z_i}')\n",
    "    axs[0, 2].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[0, 2].axis('off')\n",
    "\n",
    "    axs[0, 3].set_title(f'Overlay: {H}, {z_i}')\n",
    "    axs[0, 3].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[0, 3].imshow(image, alpha=overlay_alpha)\n",
    "    axs[0, 3].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_overlay(image,\n",
    "                 attribution_mask,\n",
    "                 H=0,\n",
    "                 z_i=0,\n",
    "                 cmap=None,\n",
    "                 overlay_alpha=0.4):\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=1, squeeze=False, figsize=(4, 4))\n",
    "    axs[0, 0].set_title(f'Overlay: {H}, {z_i}')\n",
    "    axs[0, 0].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[0, 0].imshow(image, alpha=overlay_alpha)\n",
    "    axs[0, 0].axis('off')\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_images(x):\n",
    "    outputs = [\n",
    "        model.model.get_layer('normal_variational').output,\n",
    "        model.model.get_layer('normal_variational_1').output,\n",
    "        model.model.get_layer('normal_variational_2').output,\n",
    "        model.model.get_layer('normal_variational_3').output\n",
    "    ]\n",
    "    encoder = tf.keras.Model(model.model.inputs, outputs)\n",
    "    return encoder.predict(x)\n",
    "\n",
    "def reconstruct_images(x):\n",
    "    return model.model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encode the samples\n",
    "x = data_loader.get_train_data().shuffle(1000).take(1)\n",
    "z = tf.convert_to_tensor(embed_images(x))\n",
    "\n",
    "# get the original samples reconstruction\n",
    "x_hat = reconstruct_images(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(x)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_id = 8  # < 16 we're only grabbing one batch at a time\n",
    "plt.subplot(121)\n",
    "plt.imshow(list(x)[0][0][sample_id])\n",
    "plt.subplot(122)\n",
    "plt.imshow(x_hat[sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_level = 3\n",
    "encoding_axis = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.convert_to_tensor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_latentvar(Z, H, z_i, alphas, zdim=10):\n",
    "    mods = []\n",
    "    for h in range(len(Z)):\n",
    "        if h == H:\n",
    "            z = Z[h]\n",
    "            mod = tf.concat([\n",
    "                tf.repeat(\n",
    "                    [z], 10, axis=0)[:,-1:z_i],\n",
    "                alphas[:, tf.newaxis],\n",
    "                tf.repeat(\n",
    "                    [z], 10, axis=0)[:, z_i:-1]], axis=1)\n",
    "            mods.append(mod)\n",
    "        else:\n",
    "            z = Z[h]\n",
    "            mod = tf.repeat([z], 10, axis=0)\n",
    "            mods.append(mod)\n",
    "\n",
    "    return mods\n",
    "\n",
    "def compute_gradients(latent_vars):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(latent_vars)\n",
    "        logits = model.decoder([latent_vars[0], latent_vars[1], latent_vars[2], latent_vars[3]])\n",
    "        images = tf.nn.tanh(logits)\n",
    "    return tape.gradient(images, logits)\n",
    "\n",
    "\n",
    "def integral_approximation(gradients):\n",
    "    # riemann_trapezoidal\n",
    "    grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
    "    integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
    "    return integrated_gradients\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "def integrated_gradients(encoding, H=0, z_i=0, m_steps=300, batch_size=10, lim=1.):\n",
    "\n",
    "    # Generate traversal steps\n",
    "    traversal_steps = tf.linspace(start=0.0, stop=lim, num=m_steps)\n",
    "    \n",
    "\n",
    "    # Accumulate gradients across batches\n",
    "    integrated_gradients = 0.0\n",
    "\n",
    "    # Batch traversals\n",
    "    ds = tf.data.Dataset.from_tensor_slices(traversal_steps).batch(batch_size)\n",
    "\n",
    "    for batch in ds:\n",
    "        batch_interpolated_inputs = interpolate_latentvar(Z=encoding, H=H, z_i=z_i, alphas=batch)\n",
    "        batch_gradients = compute_gradients(batch_interpolated_inputs)\n",
    "        return batch_gradients\n",
    "        integrated_gradients += integral_approximation(gradients=batch_gradients)\n",
    "    \n",
    "    return tf.abs(lim) * integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for att in attributions:\n",
    "    try:\n",
    "        print(att.shape)\n",
    "    except AttributeError:\n",
    "        print(att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute atributions by integrating the gradients\n",
    "attributions = integrated_gradients(z[:,sample_id,:], H=hierarchical_level, z_i=encoding_axis)\n",
    "\n",
    "# visualize the attributions\n",
    "attributions_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)\n",
    "\n",
    "_ = plot_img_attributions(image=x_hat[sample_id],\n",
    "                          attribution_mask=attributions_mask,\n",
    "                          H=hierarchical_level,\n",
    "                          z_i=encoding_axis,\n",
    "                          cmap=plt.cmap.vridis,\n",
    "                          overlay_alpha=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
