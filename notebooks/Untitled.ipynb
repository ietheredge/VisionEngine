{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 512\n",
    "input_dim = (256,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(tf.keras.layers.Layer):\n",
    "    def __init__(self, c, **kwargs):\n",
    "        super(conv_block, self).__init__(**kwargs)\n",
    "        self.c = c\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.cb = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(\n",
    "                self.c // 2,\n",
    "                kernel_size=3,\n",
    "                padding='same'\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                self.c,\n",
    "                kernel_size=3,\n",
    "                padding='same'\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish')\n",
    "        ])\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.cb(layer_inputs)\n",
    "\n",
    "    def comput_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'c': self.c,\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(conv_block, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class encoder_cell(tf.keras.layers.Layer):\n",
    "    def __init__(self, cs):\n",
    "        super(encoder_cell, self).__init__(**kwargs)\n",
    "        self.cs = cs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.ec = tf.keras.Sequential()\n",
    "        for cs_ in self.cs:\n",
    "            self.ec.add(self.conv_block(cs_))\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.ec(layer_inputs)\n",
    "\n",
    "    def comput_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'cs': self.cs,\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(encoder_cell, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class upsample_block(tf.keras.layers.Layer):\n",
    "    def __init__(self, c):\n",
    "        super(upsample_block, self).__init__(**kwargs)\n",
    "        self.c = c\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.ub = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                self.c,\n",
    "                kernel_size=3,\n",
    "                stride=2\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.ub(layer_inputs)\n",
    "\n",
    "    def comput_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'c': self.c,\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(upsample_block, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class decoder_cell(tf.keras.layers.Layer):\n",
    "    def __init__(self, cs):\n",
    "        super(decoder_cell, self).__init__(**kwargs)\n",
    "        self.cs = cs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dc = tf.keras.Sequential()\n",
    "        for cs_ in self.cs:\n",
    "            self.dc.add(self.upsample_block(cs_))\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.se(layer_inputs)\n",
    "\n",
    "    def comput_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'cs': self.cs\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(decoder_cell, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class encoder_residual_cell(tf.keras.layers.Layer):\n",
    "    def __init__(self, c):\n",
    "        super(encoder_residual_cell, self).__init__(**kwargs)\n",
    "        self.c = c\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.erc = tf.keras.Sequential([\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                c,\n",
    "                kernel_size=3,\n",
    "                padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                c,\n",
    "                kernel_size=3,\n",
    "                padding='same'),\n",
    "            SqueezeExcite])\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.erc(layer_inputs)\n",
    "\n",
    "    def comput_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'c': self.c\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(encoder_residual_cell, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class decoder_residual_cell(tf.keras.layers.Layer):\n",
    "    def __init__(self, c, e):\n",
    "        super(decoder_residual_cell, self).__init__(**kwargs)\n",
    "        self.c = c\n",
    "        self.e = e\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.drc = tf.keras.Sequential([\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                c * e,\n",
    "                kernel_size=1,\n",
    "                padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                c * e,\n",
    "                kernel_size=5,\n",
    "                stride=1),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                c,\n",
    "                kernel_size=1,\n",
    "                padding='same',\n",
    "                use_bias=False,\n",
    "                activation=None),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            SqueezeExcite(c)])\n",
    "\n",
    "        def call(self, layer_inputs, **kwargs):\n",
    "            return self.drc(layer_inputs)\n",
    "\n",
    "        def comput_output_shape(self, input_shape):\n",
    "            return input_shape\n",
    "\n",
    "        def get_config(self):\n",
    "            config = {\n",
    "                'c': self.c,\n",
    "                'e': self.e\n",
    "            }\n",
    "            base_config = \\\n",
    "                super(decoder_residual_cell, self).get_config()\n",
    "            return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class SqueezeExcite(tf.keras.layers.Layer):\n",
    "    def __init__(self, c, r=16, **kwargs):\n",
    "        super(SqueezeExcite, self).__init__(**kwargs)\n",
    "        self.c = c\n",
    "        self.r = r\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.se = tf.keras.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(self.c // self.r, bias=False),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(c, bias=False),\n",
    "            tf.keras.layers.Activation('sigmoid')])\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.se(layer_inputs)\n",
    "\n",
    "    def comput_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def et_config(self):\n",
    "        config = {\n",
    "            'c': self.c,\n",
    "            'r': self.r\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(SqueezeExcite, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class NouveauVAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, z_dim, input_dim):\n",
    "        super(NouveauVAE, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # encoder\n",
    "        self.enc = tf.keras.Sequential()\n",
    "\n",
    "        self.enc.add(tf.keras.layers.Input(shape=self.input_dim))\n",
    "\n",
    "        encoder_stack = [\n",
    "            encoder_cell([self.z_dim // 16, self.z_dim // 8]),\n",
    "            encoder_cell([self.z_dim // 4, self.z_dim // 2]),\n",
    "            encoder_cell([self.z_dim])\n",
    "        ]\n",
    "        encoder_res_stack = [\n",
    "            encoder_residual_cell(self.z_dim // 8),\n",
    "            encoder_residual_cell(self.z_dim // 2),\n",
    "            encoder_residual_cell(self.z_dim)\n",
    "        ]\n",
    "\n",
    "        for e, r in zip(encoder_stack, encoder_res_stack):\n",
    "            x = r()(e)\n",
    "            self.enc.add(x)\n",
    "\n",
    "        self.condition_x = tf.keras.layers.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.Conv2D(self.z_dim * 2)\n",
    "        ])\n",
    "\n",
    "        self.enc.add(self.condition_x)\n",
    "\n",
    "        # decoder\n",
    "        self.dec = tf.keras.Sequential()\n",
    "        self.dec.add(tf.keras.layers.Input(shape=self.z_dim * 2))\n",
    "        decoder_stack = [\n",
    "            decoder_cell([z_dim // 2]),\n",
    "            decoder_cell([z // 4, z // 8]),\n",
    "            decoder_cell([z // 16, z // 32])\n",
    "        ]\n",
    "        decoder_res_stack = [\n",
    "            decoder_residual_cell(z_dim // 2, e=1),\n",
    "            decoder_residual_cell(z_dim // 8, e=2),\n",
    "            decoder_residual_cell(z_dim // 32, e=4),\n",
    "        ]\n",
    "\n",
    "        for d, r in zip(decoder_stack, decoder_res_stack):\n",
    "            x = r(d)\n",
    "            self.dec.add(x)\n",
    "\n",
    "        self.x_hat = tf.keras.layers.Conv2D(3, kernel_size=1)\n",
    "\n",
    "        self.dec.add(self.x_hat)\n",
    "    \n",
    "\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.z_dim))\n",
    "        return self.decode(eps, appy_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mu, logvar = tf.split(self.encoder(x), num_or_size_of_splits=2, axis=1)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        eps = tf.random.normal(shape=mu.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decode(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'kwargs' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-fa22c1f4e750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m random_vector_for_generation = tf.random.normal(\n\u001b[1;32m      8\u001b[0m     shape=[num_examples_to_generate, z_dim])\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNouveauVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-6f3a0b100603>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, z_dim, input_dim)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         encoder_stack = [\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mencoder_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0mencoder_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mencoder_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-6f3a0b100603>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mencoder_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kwargs' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, z_dim])\n",
    "model = NouveauVAE(z_dim, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.2",
   "language": "python",
   "name": "tf2.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}