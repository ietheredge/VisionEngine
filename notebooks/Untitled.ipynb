{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VisionEngine.utils.config import process_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "\n",
    "    # save the checkpoint to the path defined in the config file\n",
    "    def save(self, checkpoint_path):\n",
    "        if self.model is None:\n",
    "            raise Exception(\"You need to build the model first.\")\n",
    "\n",
    "        print(\"Saving model...\")\n",
    "        self.model.save_weights(checkpoint_path)\n",
    "        print(\"Model saved\")\n",
    "\n",
    "    # load the experiment from the path defined in the config file\n",
    "    def load(self, checkpoint_path):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def build_model(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "class SqueezeExcite(tf.keras.layers.Layer):\n",
    "    def __init__(self, c, r=16, **kwargs):\n",
    "        super(SqueezeExcite, self).__init__(**kwargs)\n",
    "        self.c = c\n",
    "        self.r = r\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.se = tf.keras.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(self.c // self.r, use_bias=False),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(self.c, use_bias=False),\n",
    "            tf.keras.layers.Activation('sigmoid')])\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.se(layer_inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'c': self.c,\n",
    "            'r': self.r\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(SqueezeExcite, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class SpectralNormalization(tf.keras.layers.Wrapper):\n",
    "    def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):\n",
    "        self.iteration = iteration\n",
    "        self.eps = eps\n",
    "        self.do_power_iteration = training\n",
    "        if not isinstance(layer, tf.keras.layers.Layer):\n",
    "            raise ValueError(\n",
    "                'Please initialize `TimeDistributed` layer with a '\n",
    "                '`Layer` instance. You passed: {input}'.format(input=layer))\n",
    "        super(SpectralNormalization, self).__init__(layer, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.layer.build(input_shape)\n",
    "\n",
    "        self.w = self.layer.kernel\n",
    "        self.w_shape = self.w.shape.as_list()\n",
    "\n",
    "        self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),\n",
    "                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n",
    "                                 trainable=False,\n",
    "                                 name='sn_v',\n",
    "                                 dtype=tf.float32)\n",
    "\n",
    "        self.u = self.add_weight(shape=(1, self.w_shape[-1]),\n",
    "                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n",
    "                                 trainable=False,\n",
    "                                 name='sn_u',\n",
    "                                 dtype=tf.float32)\n",
    "\n",
    "        super(SpectralNormalization, self).build()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        self.update_weights()\n",
    "        output = self.layer(inputs)\n",
    "        self.restore_weights()  # Restore weights because of this formula \"W = W - alpha * W_SN`\"\n",
    "        return output\n",
    "    \n",
    "    def update_weights(self):\n",
    "        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n",
    "        \n",
    "        u_hat = self.u\n",
    "        v_hat = self.v  # init v vector\n",
    "\n",
    "        if self.do_power_iteration:\n",
    "            for _ in range(self.iteration):\n",
    "                v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))\n",
    "                v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)\n",
    "\n",
    "                u_ = tf.matmul(v_hat, w_reshaped)\n",
    "                u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)\n",
    "\n",
    "        sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))\n",
    "        self.u.assign(u_hat)\n",
    "        self.v.assign(v_hat)\n",
    "\n",
    "        self.layer.kernel.assign(self.w / sigma)\n",
    "\n",
    "    def restore_weights(self):\n",
    "        self.layer.kernel.assign(self.w)\n",
    "\n",
    "\n",
    "class PerceptualLossLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, perceptual_loss_model,\n",
    "                 pereceptual_loss_layers, perceptual_loss_layer_weights,\n",
    "                 model_input_shape, name, **kwargs):\n",
    "        super(PerceptualLossLayer, self).__init__(**kwargs)\n",
    "        self.loss_model_type = perceptual_loss_model\n",
    "        self.layers = pereceptual_loss_layers\n",
    "        self.layer_weights = perceptual_loss_layer_weights\n",
    "        self.model_input_shape = [256, 256, 3]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.loss_model_type == 'vgg':\n",
    "            self.loss_model_ = tf.keras.applications.VGG16(\n",
    "                weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=self.model_input_shape\n",
    "                )\n",
    "            self.loss_model_.trainable = False\n",
    "\n",
    "            for layer in self.loss_model_.layers:\n",
    "                layer.trainable = False\n",
    "\n",
    "            self.loss_layers = [\n",
    "                tf.keras.layers.BatchNormalization()(self.loss_model_.layers[i].output)\n",
    "                for i in self.layers\n",
    "                ]\n",
    "\n",
    "            self.loss_model = tf.keras.Model(\n",
    "                self.loss_model_.inputs,\n",
    "                self.loss_layers,\n",
    "                )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        super(PerceptualLossLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        y_true = layer_inputs[0]\n",
    "        y_pred = layer_inputs[1]\n",
    "\n",
    "        self.sample_ = self.loss_model(y_true)\n",
    "        self.reconstruction_ = self.loss_model(y_pred)\n",
    "\n",
    "        self.perceptual_loss = 0.\n",
    "        for i in range(len(self.reconstruction_)):\n",
    "            shape = tf.cast(tf.shape(self.reconstruction_[i]), dtype='float32')\n",
    "            self.perceptual_loss += tf.math.reduce_mean(\n",
    "                self.layer_weights[i] *\n",
    "                (tf.math.reduce_sum(tf.math.square(self.sample_[i] - self.reconstruction_[i])) /\n",
    "                    (shape[-1] * shape[1] * shape[1]))\n",
    "            )\n",
    "\n",
    "        perceptual_loss = tf.cast(self.perceptual_loss, dtype='float32')\n",
    "        self.add_loss(perceptual_loss)\n",
    "        self.add_metric(perceptual_loss, 'mean', 'perceptual_loss')\n",
    "\n",
    "        return [y_true, y_pred]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'perceptual_loss_model': self.loss_model_type,\n",
    "            'pereceptual_loss_layers': self.layers,\n",
    "            'perceptual_loss_layer_weights':\n",
    "                self.layer_weights,\n",
    "            'model_input_shape': self.model_input_shape,\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(PerceptualLossLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class NormalVariational(tf.keras.layers.Layer):\n",
    "    def __init__(self, size=2, mu_prior=0., sigma_prior=1.,\n",
    "                    use_kl=False, kl_coef=1.0,\n",
    "                    use_mmd=True, mmd_coef=100.0, name=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mu_layer = tf.keras.layers.Dense(size)\n",
    "        self.sigma_layer = tf.keras.layers.Dense(size)\n",
    "        if use_kl is True:\n",
    "            # self.sigma_layer = tf.keras.layers.Dense(size)\n",
    "            self.kl_coef = tf.Variable(kl_coef, trainable=False, name='kl_coef')\n",
    "        self.mu_prior = tf.constant(mu_prior, dtype=tf.float32, shape=(size,))\n",
    "        self.sigma_prior = tf.constant(\n",
    "            sigma_prior, dtype=tf.float32, shape=(size,)\n",
    "            )\n",
    "\n",
    "        self.use_kl = use_kl\n",
    "        self.use_mmd = use_mmd\n",
    "        self.mmd_coef = mmd_coef\n",
    "        self.kernel_f = self._rbf\n",
    "\n",
    "    def _rbf(self, x, y):\n",
    "        x_size = tf.shape(x)[0]\n",
    "        y_size = tf.shape(y)[0]\n",
    "        dim = tf.shape(x)[1]\n",
    "        tiled_x = tf.tile(tf.reshape(x, tf.stack([x_size, 1, dim])),\n",
    "                          tf.stack([1, y_size, 1]))\n",
    "\n",
    "        tiled_y = tf.tile(tf.reshape(y, tf.stack([1, y_size, dim])),\n",
    "                          tf.stack([x_size, 1, 1]))\n",
    "\n",
    "        return tf.exp(-tf.reduce_mean(tf.square(tiled_x - tiled_y), axis=2) /\n",
    "                      tf.cast(dim, tf.float32))\n",
    "\n",
    "    def use_kl_divergence(self, q_mu, q_sigma, p_mu, p_sigma):\n",
    "        r = q_mu - p_mu\n",
    "        kl = self.kl_coef * tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                tf.math.log(p_sigma) -\n",
    "                tf.math.log(q_sigma) -\n",
    "                .5 * (1. - (q_sigma**2 + r**2) / p_sigma**2), axis=1\n",
    "                )\n",
    "            )\n",
    "        self.add_loss(kl)\n",
    "        self.add_metric(kl, 'mean', 'kl_divergence')\n",
    "\n",
    "    def add_mm_discrepancy(self, z, z_prior):\n",
    "        k_prior = self.kernel_f(z_prior, z_prior)\n",
    "        k_post = self.kernel_f(z, z)\n",
    "        k_prior_post = self.kernel_f(z_prior, z)\n",
    "        mmd = tf.reduce_mean(k_prior) + \\\n",
    "            tf.reduce_mean(k_post) - \\\n",
    "            2 * tf.reduce_mean(k_prior_post)\n",
    "\n",
    "        mmd = tf.multiply(self.mmd_coef,  mmd, name='mmd')\n",
    "        self.add_loss(mmd)\n",
    "        self.add_metric(mmd, 'mean', 'mmd_discrepancy')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.use_mmd:\n",
    "            mu = self.mu_layer(inputs)\n",
    "            log_sigma = self.sigma_layer(inputs)\n",
    "            sigma_square = tf.exp(log_sigma * 0.5)\n",
    "            z = mu + (log_sigma * tf.random.normal(shape=tf.shape(sigma_square)))\n",
    "            z_prior = tfp.distributions.MultivariateNormalDiag(\n",
    "                self.mu_prior, self.sigma_prior\n",
    "                ).sample(tf.shape(z)[0])\n",
    "            self.add_mm_discrepancy(z, z_prior)\n",
    "\n",
    "        if self.use_kl:\n",
    "            mu = self.mu_layer(inputs)\n",
    "            log_sigma = self.sigma_layer(inputs)\n",
    "            sigma_square = tf.exp(log_sigma * 0.5)\n",
    "            self.use_kl_divergence(\n",
    "                mu,\n",
    "                sigma_square,\n",
    "                self.mu_prior,\n",
    "                self.sigma_prior)\n",
    "\n",
    "        return z\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(NormalVariational, self).get_config()\n",
    "        config = {\n",
    "            'use_kl': self.use_kl,\n",
    "            'use_mmd': self.use_mmd,\n",
    "            'mmd_coef': self.mmd_coef,\n",
    "            'kernel_f': self.kernel_f,\n",
    "        }\n",
    "\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class SaltAndPepper(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio=0.9, **kwargs):\n",
    "        super(SaltAndPepper, self).__init__(**kwargs)\n",
    "        self.masking = True\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        def noised():\n",
    "            shp = tf.keras.backend.shape(inputs)[1:]\n",
    "            mask_select = tf.keras.backend.random_binomial(\n",
    "                shape=shp, p=self.ratio)\n",
    "\n",
    "            # salt and pepper have the same chance\n",
    "            mask_noise = tf.keras.backend.random_binomial(shape=shp, p=0.1)\n",
    "            out = (inputs * (mask_select)) + mask_noise\n",
    "            return out\n",
    "\n",
    "        return tf.keras.backend.in_train_phase(\n",
    "            noised, inputs, training=training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'ratio': self.ratio,\n",
    "                  'masking': self.masking}\n",
    "        base_config = super(SaltAndPepper, self).get_config()\n",
    "\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class Encoder(BaseModel):\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__(config)\n",
    "        self.make_encoder()\n",
    "\n",
    "    def make_encoder(self):\n",
    "        with tf.name_scope('encoder'):\n",
    "            self.encoder_inputs = tf.keras.layers.Input(\n",
    "                shape=self.config.model.input_shape, name='input')\n",
    "\n",
    "            if self.config.model.denoise is True:\n",
    "                with tf.name_scope('noise_layer'):\n",
    "                    noise_layers = tf.keras.Sequential([\n",
    "                        SaltAndPepper(),\n",
    "                        tf.keras.layers.GaussianNoise(self.config.model.noise_ratio)\n",
    "                        ], name='noise_layer')\n",
    "\n",
    "                    noisy_inputs = noise_layers(self.encoder_inputs)\n",
    "\n",
    "            with tf.name_scope('z_1'):\n",
    "                h_1_layers = tf.keras.Sequential([\n",
    "                    tf.keras.layers.Input(self.config.model.input_shape),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        8, 3,  padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        16, 3,  padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        16, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        32, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    tf.keras.layers.AveragePooling2D()], name='h_1')\n",
    "                if self.config.modeul.denoise is True:\n",
    "                    h_1 = h_1_layers(noisy_inputs)\n",
    "                else:\n",
    "                    h_1 = h_1_layers(self.encoder_inputs)\n",
    "\n",
    "                h_1_flatten = SqueezeExcite(c=32)(h_1)\n",
    "\n",
    "            with tf.name_scope('z_2'):\n",
    "                h_2_layers = tf.keras.Sequential([\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        32, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        64, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        64, 3, padding='same')),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        128, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    tf.keras.layers.AveragePooling2D(),\n",
    "                ], name='h_2')\n",
    "\n",
    "                h_2 = h_2_layers(h_1)\n",
    "                h_2_flatten = SqueezeExcite(c=128)(h_2)\n",
    "\n",
    "            with tf.name_scope('z_3'):\n",
    "                h_3_layers = tf.keras.Sequential([\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        128, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        256, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        256, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        512, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    tf.keras.layers.AveragePooling2D(),\n",
    "                ], name='h_3')\n",
    "\n",
    "                h_3 = h_3_layers(h_2)\n",
    "                h_3_flatten = SqueezeExcite(c=512)(h_3)\n",
    "\n",
    "            with tf.name_scope('z_4'):\n",
    "                h_4_layers = tf.keras.Sequential([\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        512, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        1024, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        1024, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        2048, 3, padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.encoder_activations),\n",
    "                    tf.keras.layers.AveragePooling2D()], name='h_4')\n",
    "\n",
    "                h_4 = h_4_layers(h_3)\n",
    "                h_4_flatten = SqueezeExcite(c=2048)(h_4)\n",
    "\n",
    "            self.encoder_outputs = [\n",
    "                h_1_flatten, h_2_flatten, h_3_flatten, h_4_flatten\n",
    "                ]\n",
    "\n",
    "            self.encoder = tf.keras.Model(\n",
    "                self.encoder_inputs, self.encoder_outputs, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/home/etheredge/Workspace/VisionEngine/VisionEngine/configs/butterfly_periodic_config.json'\n",
    "config = process_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "h_1 (Sequential)                (None, 128, 128, 32) 9099        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "h_2 (Sequential)                (None, 64, 64, 128)  141440      h_1[1][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "h_3 (Sequential)                (None, 32, 32, 512)  2225664     h_2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "h_4 (Sequential)                (None, 16, 16, 2048) 35444736    h_3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_excite (SqueezeExcite)  (None, 32)           128         h_1[1][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_excite_1 (SqueezeExcite (None, 128)          2048        h_2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_excite_2 (SqueezeExcite (None, 512)          32768       h_3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_excite_3 (SqueezeExcite (None, 2048)         524288      h_4[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 38,380,171\n",
      "Trainable params: 38,325,264\n",
      "Non-trainable params: 54,907\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(BaseModel):\n",
    "    def __init__(self, config):\n",
    "        super(Decoder, self).__init__(config)\n",
    "        self.make_decoder()\n",
    "\n",
    "    def make_decoder(self):\n",
    "        with tf.name_scope('decoder'):\n",
    "\n",
    "            self.z_1_input = tf.keras.layers.Input(\n",
    "                (self.config.model.latent_size,), name='z_1')\n",
    "\n",
    "            self.z_2_input = tf.keras.layers.Input(\n",
    "                (self.config.model.latent_size,), name='z_2')\n",
    "\n",
    "            self.z_3_input = tf.keras.layers.Input(\n",
    "                (self.config.model.latent_size,), name='z_3')\n",
    "\n",
    "            self.z_4_input = tf.keras.layers.Input(\n",
    "                (self.config.model.latent_size,), name='z_4')\n",
    "\n",
    "            with tf.name_scope('z_tilde_4'):\n",
    "                z_4 = self.z_4_input\n",
    "                z_4 = tf.keras.layers.Dense(16*16*2048, activation=None)(z_4)\n",
    "                z_4 = tf.keras.layers.Reshape((16,16,2048))(z_4)\n",
    "                \n",
    "                z_tilde_4_layers = tf.keras.Sequential([\n",
    "                    tf.keras.layers.UpSampling2D(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        2048,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        1024,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.decoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        1024,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        512,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.decoder_activations)], name='z_tilde_4')\n",
    "                z_tilde_4 = z_tilde_4_layers(z_4)\n",
    "\n",
    "            with tf.name_scope('z_tilde_3'):\n",
    "                z_3 = self.z_3_input\n",
    "                z_3 = tf.keras.layers.Dense(32*32*512, activation=None)(z_3)\n",
    "                z_3 = tf.keras.layers.Reshape((32,32,512))(z_3)\n",
    "\n",
    "                z_tilde_3_layers = tf.keras.Sequential([\n",
    "                    tf.keras.layers.UpSampling2D(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        512,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        256,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.decoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        256,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        128,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.decoder_activations)], name='z_tilde_3')\n",
    "\n",
    "                input_z_tilde_3 = tf.keras.layers.Concatenate()([z_tilde_4, z_3])\n",
    "                z_tilde_3 = z_tilde_3_layers(input_z_tilde_3)\n",
    "\n",
    "            with tf.name_scope('z_tilde_2'):\n",
    "                z_2 = self.z_2_input\n",
    "                z_2 = tf.keras.layers.Dense(64*64*128, activation=None)(z_2)\n",
    "                z_2 = tf.keras.layers.Reshape((64,64,128))(z_2)\n",
    "                                                        \n",
    "                z_tilde_2_layers = tf.keras.Sequential([\n",
    "                    tf.keras.layers.UpSampling2D(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        128,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        64,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.decoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        64,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        32,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.decoder_activations)], name='z_tilde_2')\n",
    "\n",
    "                input_z_tilde_2 = tf.keras.layers.Concatenate()([z_tilde_3, z_2])\n",
    "                z_tilde_2 = z_tilde_2_layers(input_z_tilde_2)\n",
    "\n",
    "            with tf.name_scope('z_tilde_1'):\n",
    "                z_1 = self.z_1_input\n",
    "                z_1 = tf.keras.layers.Dense(128*128*32, activation=None)(z_1)\n",
    "                z_1 = tf.keras.layers.Reshape((128,128,32))(z_1)\n",
    "                z_tilde_1_layers = tf.keras.Sequential([\n",
    "                    tf.keras.layers.UpSampling2D(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        32,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        16,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.decoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        16,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        8,\n",
    "                        kernel_size=3,\n",
    "                        padding='same')),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.Activation(self.config.model.decoder_activations),\n",
    "                    SpectralNormalization(tf.keras.layers.Conv2D(\n",
    "                        self.config.model.input_shape[2], 3, 1, padding='same')),\n",
    "                    tf.keras.layers.Activation(self.config.model.last_activation)], name='z_tilde_1')\n",
    "\n",
    "                input_z_tilde_1 = tf.keras.layers.Concatenate()([z_tilde_2, z_1])\n",
    "\n",
    "                self.decoder_outputs = z_tilde_1_layers(input_z_tilde_1)\n",
    "                self.decoder_inputs = [\n",
    "                    self.z_1_input, self.z_2_input, self.z_3_input, self.z_4_input\n",
    "                    ]\n",
    "\n",
    "            self.decoder = tf.keras.Model(\n",
    "                self.decoder_inputs,\n",
    "                self.decoder_outputs,\n",
    "                name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "z_4 (InputLayer)                [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 524288)       5767168     z_4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "z_3 (InputLayer)                [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_53 (Reshape)            (None, 16, 16, 2048) 0           dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 524288)       5767168     z_3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "z_tilde_4 (Sequential)          (None, 32, 32, 512)  70861824    reshape_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_54 (Reshape)            (None, 32, 32, 512)  0           dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_2 (InputLayer)                [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 32, 32, 1024) 0           z_tilde_4[0][0]                  \n",
      "                                                                 reshape_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 524288)       5767168     z_2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "z_tilde_3 (Sequential)          (None, 64, 64, 128)  6808320     concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_55 (Reshape)            (None, 64, 64, 128)  0           dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_1 (InputLayer)                [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 64, 64, 256)  0           z_tilde_3[0][0]                  \n",
      "                                                                 reshape_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 524288)       5767168     z_1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "z_tilde_2 (Sequential)          (None, 128, 128, 32) 430272      concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_56 (Reshape)            (None, 128, 128, 32) 0           dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 128, 128, 64) 0           z_tilde_2[0][0]                  \n",
      "                                                                 reshape_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_tilde_1 (Sequential)          (None, 256, 256, 3)  28374       concatenate_28[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 101,197,462\n",
      "Trainable params: 101,099,539\n",
      "Non-trainable params: 97,923\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 512\n",
    "input_dim = (256,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, c, **kwargs):\n",
    "        super(ConvBlock, self).__init__(**kwargs)\n",
    "        self.c = c\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.cb = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(\n",
    "                self.c // 2,\n",
    "                kernel_size=3,\n",
    "                padding='same'\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                self.c,\n",
    "                kernel_size=3,\n",
    "                padding='same'\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish')\n",
    "        ])\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.cb(layer_inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'c': self.c,\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(ConvBlock, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, cs, **kwargs):\n",
    "        super(EncoderCell, self).__init__(**kwargs)\n",
    "        self.cs = cs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.ec = tf.keras.Sequential()\n",
    "        for cs_ in self.cs:\n",
    "            self.ec.add(ConvBlock(cs_))\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.ec(layer_inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'cs': self.cs,\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(EncoderCell, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class UpsampleBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, c, **kwargs):\n",
    "        super(UpsampleBlock, self).__init__(**kwargs)\n",
    "        self.c = c\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.ub = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                self.c,\n",
    "                kernel_size=3,\n",
    "                stride=2\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.ub(layer_inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'c': self.c,\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(UpsampleBlock, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class DecoderCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, cs, **kwargs):\n",
    "        super(DecoderCell, self).__init__(**kwargs)\n",
    "        self.cs = cs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dc = tf.keras.Sequential()\n",
    "        for cs_ in self.cs:\n",
    "            self.dc.add(self.UpsampleBlock(cs_))\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.se(layer_inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'cs': self.cs\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(DecoderCell, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderResidualCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, c, **kwargs):\n",
    "        super(EncoderResidualCell, self).__init__(**kwargs)\n",
    "        self.c = c\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.erc = tf.keras.Sequential([\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                self.c,\n",
    "                kernel_size=3,\n",
    "                padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                self.c,\n",
    "                kernel_size=3,\n",
    "                padding='same'),\n",
    "            SqueezeExcite(self.c)])\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.erc(layer_inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'c': self.c\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(EncoderResidualCell, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class DecoderResidualCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, c, e, **kwargs):\n",
    "        super(DecoderResidualCell, self).__init__(**kwargs)\n",
    "        self.c = c\n",
    "        self.e = e\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.drc = tf.keras.Sequential([\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                self.c * self.e,\n",
    "                kernel_size=1,\n",
    "                padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                self.c * self.e,\n",
    "                kernel_size=5,\n",
    "                stride=1),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                self.c,\n",
    "                kernel_size=1,\n",
    "                padding='same',\n",
    "                use_use_bias=False,\n",
    "                activation=None),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            SqueezeExcite(self.c)])\n",
    "\n",
    "        def call(self, layer_inputs, **kwargs):\n",
    "            return self.drc(layer_inputs)\n",
    "\n",
    "        def compute_output_shape(self, input_shape):\n",
    "            return input_shape\n",
    "\n",
    "        def get_config(self):\n",
    "            config = {\n",
    "                'c': self.c,\n",
    "                'e': self.e\n",
    "            }\n",
    "            base_config = \\\n",
    "                super(DecoderResidualCell, self).get_config()\n",
    "            return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class SqueezeExcite(tf.keras.layers.Layer):\n",
    "    def __init__(self, c, r=16, **kwargs):\n",
    "        super(SqueezeExcite, self).__init__(**kwargs)\n",
    "        self.c = c\n",
    "        self.r = r\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.se = tf.keras.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(self.c // self.r, use_bias=False),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(self.c, use_bias=False),\n",
    "            tf.keras.layers.Activation('sigmoid')])\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.se(layer_inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'c': self.c,\n",
    "            'r': self.r\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(SqueezeExcite, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class NouveauVAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, z_dim, input_dim):\n",
    "        super(NouveauVAE, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # encoder\n",
    "#         self.enc = tf.keras.Sequential()\n",
    "\n",
    "        self.enc_inputs = tf.keras.layers.Input(shape=self.input_dim, name='input')\n",
    "\n",
    "        encoder_stack = [\n",
    "            EncoderCell([self.z_dim // 16, self.z_dim // 8]),\n",
    "            EncoderCell([self.z_dim // 4, self.z_dim // 2]),\n",
    "            EncoderCell([self.z_dim])\n",
    "        ]\n",
    "        encoder_res_stack = [\n",
    "            EncoderResidualCell(self.z_dim // 8),\n",
    "            EncoderResidualCell(self.z_dim // 2),\n",
    "            EncoderResidualCell(self.z_dim)\n",
    "        ]\n",
    "\n",
    "        for e, r in zip(encoder_stack[:1], encoder_res_stack[:1]):\n",
    "            x = r()e()(self.enc_inputs)\n",
    "            \n",
    "        for e, r in zip(encoder_stack[1:], encoder_res_stack[1:]):\n",
    "            x = r()e()(x)\n",
    "\n",
    "        self.condition_x = tf.keras.layers.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.Conv2D(self.z_dim * 2)\n",
    "        ])\n",
    "\n",
    "        self.z = self.condition_x()(x)\n",
    "        \n",
    "        \n",
    "\n",
    "        # decoder\n",
    "#         self.dec = tf.keras.Sequential()\n",
    "        self.dec.add(tf.keras.layers.Input(shape=self.z_dim * 2))\n",
    "        decoder_stack = [\n",
    "            DecoderCell([z_dim // 2]),\n",
    "            DecoderCell([z // 4, z // 8]),\n",
    "            DecoderCell([z // 16, z // 32])\n",
    "        ]\n",
    "        decoder_res_stack = [\n",
    "            DecoderResidualCell(z_dim // 2, e=1),\n",
    "            DecoderResidualCell(z_dim // 8, e=2),\n",
    "            DecoderResidualCell(z_dim // 32, e=4),\n",
    "        ]\n",
    "\n",
    "        for d, r in zip(decoder_stack, decoder_res_stack):\n",
    "            x = r(d)\n",
    "            self.dec.add(x)\n",
    "\n",
    "        self.x_hat = tf.keras.layers.Conv2D(3, kernel_size=1)\n",
    "\n",
    "        self.dec.add(self.x_hat)\n",
    "    \n",
    "\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.z_dim))\n",
    "        return self.decode(eps, appy_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mu, logvar = tf.split(self.encoder(x), num_or_size_of_splits=2, axis=1)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        eps = tf.random.normal(shape=mu.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decode(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Input has undefined rank:', TensorShape(None))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-fa22c1f4e750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m random_vector_for_generation = tf.random.normal(\n\u001b[1;32m      8\u001b[0m     shape=[num_examples_to_generate, z_dim])\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNouveauVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-6af911868161>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, z_dim, input_dim)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_res_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         self.condition_x = tf.keras.layers.Sequential([\n",
      "\u001b[0;32m~/opt/miniconda3/envs/VisionEngine/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-6af911868161>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, layer_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/VisionEngine/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/VisionEngine/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/VisionEngine/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;31m# Eager execution on data tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n",
      "\u001b[0;32m~/opt/miniconda3/envs/VisionEngine/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/VisionEngine/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input has undefined rank:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m     \u001b[0mndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Input has undefined rank:', TensorShape(None))"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, z_dim])\n",
    "model = NouveauVAE(z_dim, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('VisionEngine': conda)",
   "language": "python",
   "name": "python37664bitvisionengineconda838d932a94804d329f926ede73ba6fa3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
