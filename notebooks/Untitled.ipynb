{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 512\n",
    "input_dim = (256,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NouveauVAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, z_dim, input_dim):\n",
    "        super(NouveauVAE, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # encoder\n",
    "        self.enc = tf.keras.Sequential()\n",
    "\n",
    "        self.enc.add(tf.keras.layers.Input(shape=self.input_dim))\n",
    "\n",
    "        encoder_stack = [\n",
    "            self.encoder_cell([self.z_dim // 16, self.z_dim // 8]),\n",
    "            self.encoder_cell([self.z_dim // 4, self.z_dim // 2]),\n",
    "            self.encoder_cell([self.z_dim])\n",
    "        ]\n",
    "        encoder_res_stack = [\n",
    "            self.encoder_residual_cell(self.z_dim // 8),\n",
    "            self.encoder_residual_cell(self.z_dim // 2),\n",
    "            self.encoder_residual_cell(self.z_dim)\n",
    "        ]\n",
    "\n",
    "        for e, r in zip(encoder_stack, encoder_res_stack):\n",
    "            x = r(e)\n",
    "            self.enc.add(x)\n",
    "\n",
    "        self.condition_x = tf.keras.layers.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.Conv2D(self.z_dim * 2)\n",
    "        ])\n",
    "\n",
    "        self.enc.add(self.condition_x)\n",
    "        \n",
    "        # decoder\n",
    "        self.dec = tf.keras.Sequential()\n",
    "        self.dec.add(tf.keras.layers.Input(shape=self.z_dim * 2))\n",
    "        decoder_stack = [\n",
    "            self.decoder_cell([z_dim // 2]),\n",
    "            self.decoder_cell([z // 4, z // 8]),\n",
    "            self.decoder_cell([z // 16, z // 32])\n",
    "        ]\n",
    "        decoder_res_stack = [\n",
    "            self.decoder_residual_cell(z_dim // 2, e=1),\n",
    "            self.decoder_residual_cell(z_dim // 8, e=2),\n",
    "            self.decoder_residual_cell(z_dim // 32, e=4),\n",
    "        ]\n",
    "\n",
    "        for d, r in zip(decoder_stack, decoder_res_stack):\n",
    "            x = r(d)\n",
    "            self.dec.add(x)\n",
    "\n",
    "        self.x_hat = tf.keras.layers.Conv2D(3, kernel_size=1)\n",
    "\n",
    "        self.dec.add(self.x_hat)\n",
    "    \n",
    "\n",
    "    def conv_block(self, c):\n",
    "        cb = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(\n",
    "                c // 2,\n",
    "                kernel_size=3,\n",
    "                padding='same'\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                c,\n",
    "                kernel_size=3,\n",
    "                padding='same'\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish')\n",
    "        ])\n",
    "        return cb\n",
    "\n",
    "    def encoder_cell(self, cs):\n",
    "        ec = tf.keras.Sequential()\n",
    "        for cs_ in cs:\n",
    "            ec.add(self.conv_block(cs_))\n",
    "        return ec\n",
    "\n",
    "    def upsample_block(self, c):\n",
    "        ub = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                c,\n",
    "                kernel_size=3,\n",
    "                stride=2\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization()\n",
    "        ])\n",
    "        return ub\n",
    "\n",
    "    def decoder_cell(self, cs):\n",
    "        dc = tf.keras.Sequential()\n",
    "        for cs_ in cs:\n",
    "            dc.add(self.upsample_block(cs_))\n",
    "        return dc\n",
    "\n",
    "    def squeeze_excite(self, c, r=16):\n",
    "        se = tf.keras.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(c // r, bias=False),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.Dense(c, bias=False),\n",
    "            tf.keras.layers.Activation('sigmoid')])\n",
    "        return se\n",
    "\n",
    "    def encoder_residual_cell(self, c):\n",
    "        erc = tf.keras.Sequential([\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                c,\n",
    "                kernel_size=3,\n",
    "                padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                c,\n",
    "                kernel_size=3,\n",
    "                padding='same')])\n",
    "        return erc\n",
    "\n",
    "    def decoder_residual_cell(self, c, e):\n",
    "        drc = tf.keras.Sequential([\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                c * e,\n",
    "                kernel_size=1,\n",
    "                padding='same'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                c * e,\n",
    "                kernel_size=5,\n",
    "                stride=1),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('swish'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                c,\n",
    "                kernel_size=1,\n",
    "                padding='same',\n",
    "                use_bias=False,\n",
    "                activation=None),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            self.squeeze_excite(c)])\n",
    "\n",
    "        return drc\n",
    "\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.z_dim))\n",
    "        return self.decode(eps, appy_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mu, logvar = tf.split(self.encoder(x), num_or_size_of_splits=2, axis=1)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        eps = tf.random.normal(shape=mu.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decode(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: <bound method NouveauVAE.squeeze_excite of <__main__.NouveauVAE object at 0x7fc8ea882d60>>",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fa22c1f4e750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m random_vector_for_generation = tf.random.normal(\n\u001b[1;32m      8\u001b[0m     shape=[num_examples_to_generate, z_dim])\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNouveauVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-9af1c0fc4c61>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, z_dim, input_dim)\u001b[0m\n\u001b[1;32m     17\u001b[0m         ]\n\u001b[1;32m     18\u001b[0m         encoder_res_stack = [\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_residual_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_residual_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_residual_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-9af1c0fc4c61>\u001b[0m in \u001b[0;36mencoder_residual_cell\u001b[0;34m(self, c)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencoder_residual_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         erc = tf.keras.Sequential([\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             tf.keras.layers.Conv2D(\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       raise TypeError('The added layer must be '\n\u001b[0m\u001b[1;32m    173\u001b[0m                       \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                       'Found: ' + str(layer))\n",
      "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: <bound method NouveauVAE.squeeze_excite of <__main__.NouveauVAE object at 0x7fc8ea882d60>>"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, z_dim])\n",
    "model = NouveauVAE(z_dim, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.2",
   "language": "python",
   "name": "tf2.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}