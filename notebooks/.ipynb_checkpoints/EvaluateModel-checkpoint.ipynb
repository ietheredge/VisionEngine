{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VisionEngine.utils.config import process_config\n",
    "from VisionEngine.utils import factory\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from itertools import product\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import numba\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from openTSNE import TSNE\n",
    "from openTSNE.sklearn import TSNE as sklTSNE\n",
    "from openTSNE.callbacks import ErrorLogger\n",
    "\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LikeLihoodLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LikeLihoodLayer, self).__init__(**kwargs)\n",
    "        self.model_input_shape = [256, 256, 3]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(LikeLihoodLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        inputs, outputs = layer_inputs\n",
    "        mse = - tf.losses.mean_squared_error(inputs, outputs)\n",
    "        out = 1./(tf.sqrt(2.*math.pi))*tf.exp(-.5*(mse)**2.)\n",
    "        return out\n",
    "\n",
    "        return [y_true, y_pred]\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        base_config = \\\n",
    "            super(LikeLihoodLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "def sample_likelihood(x):\n",
    "    inputs = Flatten()(model.model.input)\n",
    "    outputs = Flatten()(model.model.output)\n",
    "    out = LikeLihoodLayer()([inputs, outputs])\n",
    "    lh_model = Model(model.model.input, out)\n",
    "    return lh_model.predict(x)\n",
    "\n",
    "def embed_images(x):\n",
    "    outputs = [\n",
    "        model.model.get_layer('variational_layer').output,\n",
    "        model.model.get_layer('variational_layer_1').output,\n",
    "        model.model.get_layer('variational_layer_2').output,\n",
    "        model.model.get_layer('variational_layer_3').output\n",
    "    ]\n",
    "    encoder = Model(model.model.inputs, outputs)\n",
    "    return encoder.predict(x)\n",
    "\n",
    "def reconstruct_images(x):\n",
    "    return model.model.predict(x)\n",
    "\n",
    "def imscatter(x, y, image, ax=None, zoom=1):\n",
    "    if ax is None:\n",
    "        ax = plt.gca();\n",
    "    try:\n",
    "        image = plt.imread(image);\n",
    "    except TypeError:\n",
    "        # Likely already an array...\n",
    "        pass\n",
    "    x, y = np.atleast_1d(x, y);\n",
    "    artists = [];\n",
    "    for i, (x0, y0) in enumerate(zip(x, y)):\n",
    "        im = OffsetImage(image[i], zoom=zoom);\n",
    "        ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=False);\n",
    "        artists.append(ax.add_artist(ab));\n",
    "    ax.update_datalim(np.column_stack([x, y]));\n",
    "    ax.autoscale();\n",
    "    ax.grid(False);\n",
    "    return artists\n",
    "\n",
    "def plot_im(img):\n",
    "    if config.model.last_activation == 'tanh':\n",
    "        img * 0.5 + 0.5\n",
    "        return img\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = Path('../') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Butterflies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/etheredge/Workspace/VisionEngine/checkpoints/butterflies_nouveau/2020-220-17/butterflies_nouveau.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/etheredge/Workspace/VisionEngine/VisionEngine/configs/butterfly_nouveau_config.json\"\n",
    "config = process_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = factory.create(\n",
    "            \"VisionEngine.models.\"+config.model.name\n",
    "            )(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_loader.use_generated = False\n",
    "config.data_loader.use_real = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = factory.create(\n",
    "            \"VisionEngine.data_loaders.\"+config.data_loader.name\n",
    "            )(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = embed_images(data_loader.get_test_data())\n",
    "# lh = sample_likelihood(data_loader.get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ = iter(data_loader.get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(321)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(322)\n",
    "plt.imshow(plot_im(x_hat[ID]))\n",
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(323)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(324)\n",
    "plt.imshow(plot_im(x_hat[ID]))\n",
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(325)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(326)\n",
    "plt.imshow(plot_im(x_hat[ID]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([z[0],z[1],z[2],z[3]], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vision_engine_embedding = TSNE(callbacks=ErrorLogger(), n_jobs=8, exaggeration=4, learning_rate=len(z)/12).fit(np.concatenate([z[0],z[1],z[2],z[3]], axis=1))\n",
    "h1 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[0])\n",
    "h2 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[1])\n",
    "h3 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[2])\n",
    "h4 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "images = []\n",
    "for image, label in data_loader.get_plot_data():\n",
    "    labels.append(label.numpy().decode('utf8'))\n",
    "    images.append(image.numpy().astype('uint8'))\n",
    "images = np.stack(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,10))\n",
    "\n",
    "classnames, indices = np.unique( labels, return_inverse=True)\n",
    "N = len(classnames)\n",
    "cmap = plt.cm.rainbow\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "plt.subplot(141)\n",
    "embedding = h1\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "plt.subplot(142)\n",
    "embedding = h2\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "plt.subplot(143)\n",
    "embedding = h3\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "plt.subplot(144)\n",
    "embedding = h4\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "classnames, indices = np.unique( labels, return_inverse=True)\n",
    "N = len(classnames)\n",
    "cmap = plt.cm.rainbow\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "embedding = vision_engine_embedding\n",
    "\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,80))\n",
    "# plt.scatter(vision_engine_embedding[:,0],vision_engine_embedding[:,1],c=lh, s=10000)\n",
    "# plt.colorbar()\n",
    "embedding = vision_engine_embedding\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.50);\n",
    "# fig = plt.gcf()\n",
    "# fig.savefig('what_real.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAN Generated Guppies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/etheredge/Workspace/VisionEngine/checkpoints/guppy_nouveau/2020-223-20/guppy_nouveau.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/etheredge/Workspace/VisionEngine/VisionEngine/configs/guppy_nouveau_config.json\"\n",
    "config = process_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_loader.use_generated = False\n",
    "config.data_loader.use_real = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = factory.create(\n",
    "            \"VisionEngine.data_loaders.\"+config.data_loader.name\n",
    "            )(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = embed_images(data_loader.get_test_data())\n",
    "# lh = sample_likelihood(data_loader.get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ = iter(data_loader.get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(321)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(322)\n",
    "plt.imshow(plot_im(x_hat[ID]))\n",
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(323)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(324)\n",
    "plt.imshow(plot_im(x_hat[ID]))\n",
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(325)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(326)\n",
    "plt.imshow(plot_im(x_hat[ID]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([z[0],z[1],z[2],z[3]], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vision_engine_embedding = TSNE(callbacks=ErrorLogger(), n_jobs=8, exaggeration=4, learning_rate=len(z)/12).fit(np.concatenate([z[0],z[1],z[2],z[3]], axis=1))\n",
    "h1 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[0])\n",
    "h2 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[1])\n",
    "h3 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[2])\n",
    "h4 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "images = []\n",
    "for image, label in data_loader.get_plot_data():\n",
    "    labels.append(label.numpy().decode('utf8'))\n",
    "    images.append(image.numpy().astype('uint8'))\n",
    "images = np.stack(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,10))\n",
    "\n",
    "classnames, indices = np.unique( labels, return_inverse=True)\n",
    "N = len(classnames)\n",
    "cmap = plt.cm.rainbow\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "plt.subplot(141)\n",
    "embedding = h1\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "plt.subplot(142)\n",
    "embedding = h2\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "plt.subplot(143)\n",
    "embedding = h3\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "plt.subplot(144)\n",
    "embedding = h4\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "classnames, indices = np.unique( labels, return_inverse=True)\n",
    "N = len(classnames)\n",
    "cmap = plt.cm.rainbow\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "embedding = vision_engine_embedding\n",
    "\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,80))\n",
    "# plt.scatter(vision_engine_embedding[:,0],vision_engine_embedding[:,1],c=lh, s=10000)\n",
    "# plt.colorbar()\n",
    "embedding = vision_engine_embedding\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.50);\n",
    "# fig = plt.gcf()\n",
    "# fig.savefig('what_real.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAN Generated Guppies : $\\sigma = 1e-2$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/etheredge/Workspace/VisionEngine/checkpoints/guppy_nouveau/2020-224-14/guppy_nouveau.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/etheredge/Workspace/VisionEngine/VisionEngine/configs/guppy_nouveau_config_singlemmd.json\"\n",
    "config = process_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_loader.use_generated = False\n",
    "config.data_loader.use_real = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = factory.create(\n",
    "            \"VisionEngine.data_loaders.\"+config.data_loader.name\n",
    "            )(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = embed_images(data_loader.get_test_data())\n",
    "# lh = sample_likelihood(data_loader.get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ = iter(data_loader.get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(321)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(322)\n",
    "plt.imshow(plot_im(x_hat[ID]))\n",
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(323)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(324)\n",
    "plt.imshow(plot_im(x_hat[ID]))\n",
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(325)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(326)\n",
    "plt.imshow(plot_im(x_hat[ID]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([z[0],z[1],z[2],z[3]], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vision_engine_embedding = TSNE(callbacks=ErrorLogger(), n_jobs=8, exaggeration=4, learning_rate=len(z)/12).fit(np.concatenate([z[0],z[1],z[2],z[3]], axis=1))\n",
    "h1 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[0])\n",
    "h2 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[1])\n",
    "h3 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[2])\n",
    "h4 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "images = []\n",
    "for image, label in data_loader.get_plot_data():\n",
    "    labels.append(label.numpy().decode('utf8'))\n",
    "    images.append(image.numpy().astype('uint8'))\n",
    "images = np.stack(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,10))\n",
    "\n",
    "classnames, indices = np.unique( labels, return_inverse=True)\n",
    "N = len(classnames)\n",
    "cmap = plt.cm.rainbow\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "plt.subplot(141)\n",
    "embedding = h1\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "plt.subplot(142)\n",
    "embedding = h2\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "plt.subplot(143)\n",
    "embedding = h3\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "plt.subplot(144)\n",
    "embedding = h4\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "classnames, indices = np.unique( labels, return_inverse=True)\n",
    "N = len(classnames)\n",
    "cmap = plt.cm.rainbow\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "embedding = vision_engine_embedding\n",
    "\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,80))\n",
    "# plt.scatter(vision_engine_embedding[:,0],vision_engine_embedding[:,1],c=lh, s=10000)\n",
    "# plt.colorbar()\n",
    "embedding = vision_engine_embedding\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.50);\n",
    "# fig = plt.gcf()\n",
    "# fig.savefig('what_real.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real Guppies - Finetune**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/etheredge/Workspace/VisionEngine/checkpoints/guppy_nouveau_finetune/2020-224-11/guppy_nouveau_finetune.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/etheredge/Workspace/VisionEngine/VisionEngine/configs/guppy_nouveau_finetune_config.json\"\n",
    "config = process_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_loader.use_generated = False\n",
    "config.data_loader.use_real = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = factory.create(\n",
    "            \"VisionEngine.data_loaders.\"+config.data_loader.name\n",
    "            )(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = embed_images(data_loader.get_test_data())\n",
    "# lh = sample_likelihood(data_loader.get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ = iter(data_loader.get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(321)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(322)\n",
    "plt.imshow(plot_im(x_hat[ID]))\n",
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(323)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(324)\n",
    "plt.imshow(plot_im(x_hat[ID]))\n",
    "images = images_.next()[0]\n",
    "x_hat = reconstruct_images(images)\n",
    "ID = 2\n",
    "plt.subplot(325)\n",
    "plt.imshow(plot_im(images[ID]))\n",
    "plt.subplot(326)\n",
    "plt.imshow(plot_im(x_hat[ID]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([z[0],z[1],z[2],z[3]], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vision_engine_embedding = TSNE(callbacks=ErrorLogger(), n_jobs=8, exaggeration=4, learning_rate=len(z)/12).fit(np.concatenate([z[0],z[1],z[2],z[3]], axis=1))\n",
    "h1 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[0])\n",
    "h2 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[1])\n",
    "h3 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[2])\n",
    "h4 = TSNE(callbacks=ErrorLogger(), exaggeration=4, learning_rate=len(z)/12, n_jobs=8).fit(z[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "images = []\n",
    "for image, label in data_loader.get_plot_data():\n",
    "    labels.append(label.numpy().decode('utf8'))\n",
    "    images.append(image.numpy().astype('uint8'))\n",
    "images = np.stack(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,10))\n",
    "\n",
    "classnames, indices = np.unique( labels, return_inverse=True)\n",
    "N = len(classnames)\n",
    "cmap = plt.cm.rainbow\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "plt.subplot(141)\n",
    "embedding = h1\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "plt.subplot(142)\n",
    "embedding = h2\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "plt.subplot(143)\n",
    "embedding = h3\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "plt.subplot(144)\n",
    "embedding = h4\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "classnames, indices = np.unique( labels, return_inverse=True)\n",
    "N = len(classnames)\n",
    "cmap = plt.cm.rainbow\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "embedding = vision_engine_embedding\n",
    "\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.2,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,80))\n",
    "# plt.scatter(vision_engine_embedding[:,0],vision_engine_embedding[:,1],c=lh, s=10000)\n",
    "# plt.colorbar()\n",
    "embedding = h1\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.50);\n",
    "# fig = plt.gcf()\n",
    "# fig.savefig('what_real.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,80))\n",
    "# plt.scatter(vision_engine_embedding[:,0],vision_engine_embedding[:,1],c=lh, s=10000)\n",
    "# plt.colorbar()\n",
    "embedding = h1\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.50);\n",
    "fig = plt.gcf()\n",
    "fig.savefig('what_h1_real.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,80))\n",
    "# plt.scatter(vision_engine_embedding[:,0],vision_engine_embedding[:,1],c=lh, s=10000)\n",
    "# plt.colorbar()\n",
    "embedding = h3\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.50);\n",
    "fig = plt.gcf()\n",
    "fig.savefig('what_h3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,80))\n",
    "# plt.scatter(vision_engine_embedding[:,0],vision_engine_embedding[:,1],c=lh, s=10000)\n",
    "# plt.colorbar()\n",
    "embedding = h4\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.50);\n",
    "fig = plt.gcf()\n",
    "fig.savefig('what_h4_real.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_lh_args = np.argsort(lh)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lh[ranked_lh_args[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[ranked_lh_args[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_output_folder = 'report_wppvae_gens/figures/images/{}'.format(checkpoint_path.split('/')[7])\n",
    "plot_output_folder = 'report_wppvae_gens/figures/panels{}'.format(checkpoint_path.split('/')[7])\n",
    "n_latents = 4 \n",
    "latent_size = 10\n",
    "Path(image_output_folder).mkdir(parents=True, exist_ok=True)\n",
    "Path(plot_output_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(z[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rand_samples(model, n_samples=9, num_steps=300, mu=0., sigma=1.):\n",
    "    output_folder = os.path.join(image_output_folder, 'explore_latents/random_normal/frames')\n",
    "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    sample =  [\n",
    "        np.random.multivariate_normal([mu] * latent_size,np.diag([sigma] * latent_size), n_samples)\n",
    "        ] * n_latents\n",
    "\n",
    "    for z in range(n_latents):\n",
    "        for t in range(num_steps):\n",
    "            sample[z] = np.random.multivariate_normal(\n",
    "                [mu] * latent_size, np.diag([sigma] * latent_size), n_samples)\n",
    "            generated = model.get_layer('decoder').predict(sample, batch_size=10)\n",
    "            generated = generated.reshape((n_samples, 256, 256,3))\n",
    "            image_container = Image.new('RGB', (256*3,256*3))\n",
    "            locs = list(product(range(int(np.sqrt(n_samples))),range(int(np.sqrt(n_samples)))))\n",
    "            for i in range(n_samples):\n",
    "                img = generated[i]\n",
    "                j, k = locs[i]\n",
    "                img = 255 * np.array(img)\n",
    "                img = img.astype(np.uint8)\n",
    "                image_container.paste(Image.fromarray(img.astype('uint8')), (k*256, j*256))\n",
    "            image_container.save(os.path.join(output_folder,'z{}_{:03d}.png'.format(z,t)))\n",
    "\n",
    "\n",
    "def make_traversal_from_zeros(model, n_samples=1, num_steps=11):\n",
    "    output_folder = os.path.join(image_output_folder, 'explore_latents/traversal')\n",
    "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    multipliers = np.linspace(-3,3,num=num_steps)\n",
    "\n",
    "    for z_i in range(4):\n",
    "        image_container = Image.new('RGB', (256*num_steps,256*latent_size))\n",
    "        for z_i_j in range(latent_size):\n",
    "            for s in range(num_steps):\n",
    "                sample = [np.array([[0] * latent_size]),\n",
    "                        np.array([[0] * latent_size]),\n",
    "                        np.array([[0] * latent_size]),\n",
    "                        np.array([[0] * latent_size])]\n",
    "                \n",
    "                sample[z_i][0][z_i_j] = multipliers[s]\n",
    "                generated = model.get_layer('decoder').predict(sample, batch_size=1)\n",
    "                generated = generated.reshape((256, 256,3))\n",
    "                img = 255 * np.array(generated)\n",
    "                img = img.astype(np.uint8)\n",
    "                image_container.paste(Image.fromarray(img.astype('uint8')), (s*256, z_i_j*256))\n",
    "        image_container.save(os.path.join(output_folder,'z{}.png'.format(z_i)))\n",
    "\n",
    "\n",
    "def make_traversal_from_sample(model, z, n_samples=1, num_steps=11, sample_id=0):\n",
    "    output_folder = os.path.join(image_output_folder, 'explore_latents/traversal')\n",
    "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    multipliers = np.linspace(-3,3,num=num_steps)\n",
    "    encoded_sample = [z_i[sample_id] for z_i in z]\n",
    "\n",
    "    for z_i in range(4):\n",
    "        image_container = Image.new('RGB', (256*num_steps,256*latent_size))\n",
    "        for z_i_j in range(latent_size):\n",
    "            for s in range(num_steps):\n",
    "                sample = [np.array([encoded_sample[0]]),\n",
    "                      np.array([encoded_sample[1]]),\n",
    "                      np.array([encoded_sample[2]]),\n",
    "                      np.array([encoded_sample[3]])]\n",
    "                \n",
    "                sample[z_i][0][z_i_j] = multipliers[s]\n",
    "                generated = model.get_layer('decoder').predict(sample, batch_size=1)\n",
    "                generated = generated.reshape((256, 256, 3))\n",
    "                img = 255 * np.array(generated)\n",
    "                img = img.astype(np.uint8)\n",
    "                image_container.paste(Image.fromarray(img.astype('uint8')), (s*256, z_i_j*256))\n",
    "        image_container.save(os.path.join(output_folder,'{}sample{}.png'.format(sample_id, z_i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_rand_samples(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_traversal_from_sample(model.model, z, sample_id=1350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_traversal_from_zeros(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_engine_embedding1 = TSNE(callbacks=ErrorLogger(), n_jobs=-1, learning_rate=len(z[0])/12, exaggeration=4).fit(np.array(z[0]))\n",
    "vision_engine_embedding2 = TSNE(callbacks=ErrorLogger(), n_jobs=-1, learning_rate=len(z[1])/12, exaggeration=4).fit(np.array(z[1]))\n",
    "vision_engine_embedding3 = TSNE(callbacks=ErrorLogger(), n_jobs=-1, learning_rate=len(z[2])/12, exaggeration=4).fit(np.array(z[2]))\n",
    "vision_engine_embedding4 = TSNE(callbacks=ErrorLogger(), n_jobs=-1, learning_rate=len(z[3])/12, exaggeration=4).fit(np.array(z[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,40))\n",
    "\n",
    "classnames, indices = np.unique( labels, return_inverse=True)\n",
    "N = len(classnames)\n",
    "cmap = plt.cm.rainbow\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "plt.subplot(241)\n",
    "embedding = vision_engine_embedding1\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.40);\n",
    "\n",
    "\n",
    "plt.subplot(242)\n",
    "embedding = vision_engine_embedding2\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.40);\n",
    "\n",
    "plt.subplot(243)\n",
    "embedding = vision_engine_embedding3\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.40);\n",
    "\n",
    "plt.subplot(244)\n",
    "embedding = vision_engine_embedding4\n",
    "imscatter(embedding[:, 0], embedding[:, 1], images, zoom=0.40);\n",
    "\n",
    "plt.subplot(245)\n",
    "embedding = vision_engine_embedding1\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.5,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "plt.subplot(246)\n",
    "embedding = vision_engine_embedding2\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.5,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "plt.subplot(247)\n",
    "embedding = vision_engine_embedding3\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.5,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "plt.subplot(248)\n",
    "embedding = vision_engine_embedding4\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.5,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "# fig = plt.gcf()\n",
    "# fig.savefig(os.path.join(\n",
    "#     plot_output_folder,\n",
    "#     'Zs_{}_real{}_gen{}.pdf'.format(\n",
    "#         checkpoint_path.split('/')[7],\n",
    "#         config.data_loader.use_real,\n",
    "#         config.data_loader.use_generated\n",
    "#     )\n",
    "# )\n",
    "#            )\n",
    "# fig.savefig(os.path.join(\n",
    "#     plot_output_folder,\n",
    "#     'Zs_{}_real{}_gen{}.png'.format(\n",
    "#         checkpoint_path.split('/')[7],\n",
    "#         config.data_loader.use_real,\n",
    "#         config.data_loader.use_generated\n",
    "#     )\n",
    "# )\n",
    "#            )\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_perceptual_loss_model(input_shape, layers=[13]):\n",
    "    loss_model = VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=input_shape)\n",
    "    loss_model.trainable = False\n",
    "    for layer in loss_model.layers:\n",
    "        layer.trainable = False\n",
    "    loss_layers = [ loss_model.layers[i].output\n",
    "                for i in layers\n",
    "                ]\n",
    "    return Model(loss_model.inputs,loss_layers)\n",
    "\n",
    "# @numba.jit(nopython=True, parallel=True)\n",
    "# def calculate_perceptual_distances(X):\n",
    "#     dists = np.zeros((989,989))\n",
    "#     for layer in X:\n",
    "#         layer.shape\n",
    "#         for i in range(layer.shape[0]):\n",
    "#             for j in range(layer.shape[0]):\n",
    "#                 shape = (layer[i].shape[0]*layer[i].shape[1]*layer[i].shape[2])\n",
    "#                 sqr = np.square(layer[i] - layer[j])\n",
    "#                 sm = np.sum(sqr)\n",
    "#                 val = sm / shape\n",
    "#                 dists[i,j] =+ val\n",
    "#     return dists\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True, parallel=True)\n",
    "def calculate_perceptual_distances(X):\n",
    "    norm_dists = np.zeros((len(X[0]),len(X)))\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X[0])):\n",
    "            norm_dists[j, i] = np.linalg.norm(X[i][j].flatten())\n",
    "    return norm_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptual_model = make_perceptual_loss_model((256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perception = perceptual_model.predict(data_loader.get_test_data()[0], batch_size=5)\n",
    "perceptual_dists = calculate_perceptual_distances(perception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image_embedding = TSNE(callbacks=ErrorLogger(), n_jobs=-1, learning_rate=len(z[0])/12, exaggeration=4).fit(images.flatten())\n",
    "perceptual_embedding = TSNE(callbacks=ErrorLogger(), n_jobs=-1, learning_rate=len(z[0])/12, exaggeration=4).fit(perceptual_dists)\n",
    "vision_engine_embedding = TSNE(callbacks=ErrorLogger(), n_jobs=-1, learning_rate=len(z[3])/12, exaggeration=4).fit(np.concatenate([z[0], z[1], z[2], z[3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames, indices = np.unique( labels, return_inverse=True)\n",
    "N = len(classnames)\n",
    "cmap = plt.cm.rainbow\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "plt.figure(figsize=(40,40))\n",
    "\n",
    "plt.subplot(231)\n",
    "embedding = raw_image_embedding\n",
    "imscatter(embedding[:, 0], embedding[:, 1], data_loader.get_test_data()[0], zoom=0.40);\n",
    "plt.subplot(234)\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.5,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "plt.subplot(232)\n",
    "embedding = perceptual_embedding\n",
    "imscatter(embedding[:, 0], embedding[:, 1], data_loader.get_test_data()[0], zoom=0.40);\n",
    "plt.subplot(235)\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.5,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "plt.subplot(233)\n",
    "embedding = vision_engine_embedding\n",
    "classnames, indices = np.unique(y_train, return_inverse=True)\n",
    "plt.subplot(236)\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], alpha=0.5,\n",
    "        c=indices, cmap=cmap, norm=norm, s=400)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join(\n",
    "    plot_output_folder,\n",
    "    'compare_methods_{}.pdf'.format(\n",
    "        checkpoint_path.split('/')[7]\n",
    "    )\n",
    ")\n",
    "fig.savefig(os.path.join(\n",
    "    plot_output_folder,\n",
    "    'compare_methods_{}.png'.format(\n",
    "        checkpoint_path.split('/')[7]\n",
    "    )\n",
    ")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('VisionEngine': conda)",
   "language": "python",
   "name": "python37664bitvisionengineconda838d932a94804d329f926ede73ba6fa3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
